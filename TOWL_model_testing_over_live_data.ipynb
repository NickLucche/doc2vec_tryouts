{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models on live-like version documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in new json:  96\n",
      "Number of documents in new json:  604\n"
     ]
    }
   ],
   "source": [
    "# fetch data\n",
    "import json\n",
    "filenames = ['blockchain.json', 'industria_4.0.json']\n",
    "\n",
    "with open(filenames[0], 'r') as outfile:\n",
    "    json_data = json.load(outfile)\n",
    "#print(\"Length of the json file: {0}, type: {1}\".format(len(json_data), type(json_data)))\n",
    "\n",
    "## let's now retrieve the meaningful part of the json document\n",
    "# response{}--->docs[]\n",
    "\n",
    "docs = json_data['response']['docs']\n",
    "print(\"Number of documents in new json: \",len(docs))\n",
    "\n",
    "# open file 2 and do the same things\n",
    "with open(filenames[1], 'r') as outfile:\n",
    "    json_data = json.load(outfile)\n",
    "\n",
    "docs = docs + json_data['response']['docs']\n",
    "print(\"Number of documents in new json: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New length after removing docs:  412\n"
     ]
    }
   ],
   "source": [
    "## many documents have a failed abstract, let's remove them\n",
    "to_check = ' Questo sito web utilizza cookie tecnici e, previo Suo consenso, cookie di profilazione,'\n",
    "docs = [doc for i, doc in enumerate(docs) if not(to_check.strip() in doc['abstract'][0].strip())]\n",
    "\n",
    "print(\"New length after removing docs: \", len(docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Length:  384\n",
      "['Il filo conduttore delle risposte dei giovani su come sarà il lavoro 4.0 ha certamente a che fare con il concetto di smart working: è flessibile, richiede diverse modalità di collaborazione, la parole chiave indicata da molti è condivisione.\\nAbbiamo posto la domanda a quelli che iniziano ad essere, o saranno, i protagonisti del mondo lavoro 4.0, ovvero i giovani che studiano le Stem o si occupano già di digitale, intervistati fra i partecipanti a Campus Party 2018, l’evento itinerante che raccoglie giovani di tutto il mondo per “costruire il Codice sorgente del mondo del futuro” e ha fatto tappa in Italia nello scorso mese di luglio.\\nL’Industria 4.0 viene vista come occasione di digitalizzazione e di sviluppo, i giovani ingegneri 30enni illustrano le prospettive dell’auto del futuro, ma anche di diverse modalità di organizzazione del lavoro (per esempio, in termini di efficienza del cambio di turno negli ospedali). Ci sono anche stereotipi che si ripropongono: studi ingegneristici e professioni del digitale molto al maschile, con le donne che invece tendono a scegliere i campi più creativi della rivoluzione digitale.\\nCi sono anche considerazioni amare, come quella di Giovanni, ingegnere aeronautico di 24 anni: «nel mondo del lavoro di oggi conta maggiormente la nomea piuttosto che le reali competenze, e penso che non sia una cosa che nel futuro cambierà molto». Positiva però la vision del contributo delle tecnologie, che consentiranno di ottimizzare il modo di lavorare, ad esempio consentendo la formazione di team che lavorano anche a grande distanza. Davide, ingegnere meccanico, 26 anni, ritiene che «il mondo del lavoro del futuro dipenda da tanti fattori. L’avanzamento tecnologico è molto rapido, da qui a pochi anni avremo un’industria molto diversa da oggi». Significa anche spazio all’innovazione. Nel campo dei motori, il settore deve abbandonare gli standard attuali, puntando su motori alternativi, ibridi. I motori elettrici li vedo ancora un po’ lontano, ma è certo che entro pochi anni vedremo grandi cambiamenti nel settore».\\nSara, 22 anni, infermiera, si sofferma istintivamente sulle prospettive organizzative. «La tecnologia può implementare l’assistenza, lasciare più spazio alla componente personale del rapporto con il paziente o con l’equipe di lavoro. E può incidere su fattori organizzativi. Per esempio, in ospedale le consegne, ovvero il cambio di turno fra diverse equipe o persone, diventeranno più veloci ed efficaci. Oggi abbiamo ancora fogli di carta, che si perdono, informazioni tralasciate. Con un database nel quale ognuno inserisce i suoi dati si risolve il problema e si ottimizzano i tempi».\\nPer Mirco, 35 anni, attivo nel settore Fintech, «il lavoro 4.0 è senza nessun capo se non te stesso. Bisogna scegliere un settore, e scegliere delle partnership, lavorando tutti insieme su vari business». Alessandro, 30 anni, condivide: «la chiave del lavoro del futuro è la condivisione. Il mondo consente connessioni a chilometri di distanza, di conoscere continuamente persone». Questo meccanismo porta alla continua formazione in un mercato che vede nascere rapidamente figure professionali. Pensiamo a Facebook, propone Alessandro, 23 anni, «pochi anni fa offriva una sola possibilità di lavoro, il Facebook marketer. Oggi c’è bisogno del community manager, dell’adv, di chi analizza i numeri. Ci sono almeno quattro o cinque professionalità diverse. La collaborazione porta a focalizzarsi su qualcosa, con condivisione di menti e di lavoro».\\nMassimiliano, 27 anni, individua il nesso fra condivisione e innovazione: «non siamo più nell’era dell’industrializzazione, ma del futurismo, delle invenzioni, delle creazioni. Il concetto chiave, è la condivisione».\\nSalendo con l’età, è passando dai 20enni ai 30enni, cambia il sentimento nei confronti del mondo del lavoro. Meno visionari, più giovani preoccupati per il futuro. Silvia, 30 anni, si occupa di formazione finanziaria, teme che «il mondo cambi troppo velocemente. Io non sono una millennial, appartengo a una generazione di passaggio, che deve imparare tanto, aggiornando già oggi le competenze professionali appena acquisite. Io sento proprio l’esigenza di fermarmi per imparare dei passaggi che mi mancano».\\nGiorgio, 38 anni, è fatalista: «ho imparato ad andare avanti giorno per giorno. Dieci anni fa ho aperto la partita iva immaginando che dooo 10 anni avrei avuto un studio grafico avviato, invece sono ancora free lance». Eleonora, 40 anni, vede il lavoro del futuro «più agile, rimodulabile, modellabile. Molto diverso dal lavoro dei nostri genitori». Chiara 35 anni, lo immagina «più mobile, dinamico, scalabile e creativo».\\nTutti d’accordo nell’individuare le macchine, e il digitale, come occasione di innovazione, non come fonte di proeccupazione per la sostituzione uomo-macchina. «Molte delle professioni attuali verranno a mancare, proprio nell’industria 4,0, ma anche nel digitale in generale, i lavori subiscono trasformazioni o spariscono», sottolinea Cecilia, 28 anni, la cui risposta consiste nell’avere lo scatto mentale di capire cosa sta succedendo. «Comunque il cambiamento non mi preoccupa, perchè mi occupo già di digitale».\\nArgomentata la vision di Alessandro, 28 anni: «Il lavoro del futuro sarà diverso, più connesso. Meno stabile, nel senso che non faremo un lavoro per tutta la vita. Dobbiamo quindi avere specializzazioni che consentano di variare. Si sceglie un ambito professionale, non un lavoro, e in quell’ambito bisogna crearsi diverse specializzazioni». Arianna, 26 anni, ritiene urgente la formazione per ridurre il gap generazionale: «è importante che non ci sia gente che rimane indietro, ci vuole una filo conduttore fra generazioni, in modo tale che le nuove competenze si sviluppino nel modo più omogeneo possibile». Carmine, 30 anni, condivide: «per il lavoro del futuro ci manca tanta formazione, e non parlo solo del sistema scolastico. Pensando proprio al 4.0, c’è un gap fra il livello delle tecnologie e il loro utilizzo, ad esempio in agricoltura, o nell’artigianato italiano».\\nCome si vede, emergono diverse vision, molto spesso orientate a descrivere organizzazioni del lavoro innovative.\\nUna generale domanda di formazione, a cui le imprese dovrebbero guardare con interesse in ottica di investimenti in capitale umano 4.0. Si tratta, in entrambi i casi, di tematiche che sono al centro della “nuova contrattazione” in chiave 4.0, con un’organizzazione del lavoro più snella, modelli di smart working, gli incentivi alla formazione inseriti nell’ultima legge di Bilancio aggiungendo un tassello al Piano Impresa 4.0. Una generale propensione alla condivisione di obiettivi, e al lavoro di squadra.\\n \\n Il contratto di lavoro in Industry 4.0: tutti i nodi da affrontare \\n']\n"
     ]
    }
   ],
   "source": [
    "## Adjust data format\n",
    "for i, dictionary in enumerate(docs):\n",
    "    for field in ['title', 'abstract', 'flattened_entities']:\n",
    "        if isinstance(dictionary[field], list):\n",
    "            # re-format data to hold string instead of single-list item\n",
    "            docs[i][field] = dictionary[field][0]\n",
    "# remove duplicates\n",
    "for i, doc in enumerate(docs):\n",
    "    if \"Industry 4.0 (o industria 4.0): cos'è, notizie, normative, casi studio - I4T\" in doc['title']:\n",
    "        del(docs[i])\n",
    "\"\"\"\n",
    "duplicates_indeces = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for j in range(i+1, len(docs)):\n",
    "        if docs[j]['title'] == doc['title']:\n",
    "            duplicates_indeces.append(j)\n",
    "print(\"Number of duplicates: \", len(duplicates_indeces))\n",
    "docs = [doc for i, doc in enumerate(docs) if not(i in duplicates_indeces)]\n",
    "\"\"\"\n",
    "print(\"New Length: \", len(docs))\n",
    "\n",
    "## randomize everything by shuffling the documents around\n",
    "import random\n",
    "random.shuffle(docs)\n",
    "\n",
    "for doc in docs:\n",
    "    if to_check.strip() in doc['abstract'].strip():\n",
    "        print(\"cookie doc found\")\n",
    "print([d['abstract'] for d in docs[:1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first try to infer vector from model; if that doesn't work much, let's train another model with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import  gensim\n",
    "\n",
    "MODEL_NAME = 'TestModels/d2v_TA_abstract&title0.model'\n",
    "MODEL_TWO = 'Models/d2v_TA_abstract&title0.model'\n",
    "#model = Doc2Vec.load(MODEL_NAME)\n",
    "model = Doc2Vec.load(MODEL_TWO)\n",
    "inferred_vectors = []\n",
    "# print out dimension of the vocabulary \n",
    "print(len(model.wv.vocab))\n",
    "#print(model.most_similar(positive=['re', 'donna'], negative=['uomo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# infer vectors from data\n",
    "test_corpus = [gensim.utils.simple_preprocess(d['title']+d['abstract']) for d in docs]\n",
    "print(len(test_corpus))\n",
    "inferred_vectors = [model.infer_vector(doc) for doc in test_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "# my function for performing dbscan and printing out cluster results\n",
    "def perform_dbscan(eps = 0.4, min_samples = 4, metric = 'euclidean', algorithm = 'auto', data = None, verbose = True\n",
    "                  , titles = None, print_noise = True):\n",
    "    \"\"\"perform DBSCAN over given data, using given parametrs. Returns dbscan object and clusters dictionary.\"\"\"\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm).fit(data)\n",
    "\n",
    "    # labels will print out the number of the cluster each example belongs to;\n",
    "    # -1 if the vector is considered noise (not belonging to any cluster)\n",
    "    #print(\"Labels: \", db.labels_)\n",
    "\n",
    "    # create data structure containing clusters\n",
    "    clusters_to_ret = {label:[] for label in db.labels_ if label!=-1}\n",
    "    \n",
    "    for i, label in enumerate(db.labels_):\n",
    "        if label != -1: #ignore noise points\n",
    "            clusters_to_ret[label].append(urls[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # only do this if you need to print out the result (messy for large number of docs)\n",
    "    if verbose:\n",
    "        print(\"##Clusters##\")\n",
    "        clusters = {label: [] for label in db.labels_ if label!=-1}\n",
    "        noise = []\n",
    "        for i, label in enumerate(db.labels_):\n",
    "            if label != -1: \n",
    "                clusters[label].append(titles[i])\n",
    "            else: # save noise points\n",
    "                noise.append(titles[i])\n",
    "                \n",
    "        for label, list_ in clusters.items():\n",
    "            print(\"Cluster {0}: {1}\".format(label, list_))\n",
    "        if print_noise:\n",
    "            print(\"Noise: \", noise)\n",
    "\n",
    "        print(\"DBSCAN finished.\\n\")\n",
    "    return db, clusters_to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lavoro in Industry 4.0? Per i giovani è smart e condiviso', 'Smart Contract ed obbligazioni contrattuali: formalizzare il codice per assicurare la validità del contratto - Blockchain 4innovation', 'Impresa 4.0, Gentiloni: \"Il capitale umano è fondamentale\" - CorCom', 'La progettazione virtuale di Siemens al Forum Meccatronica di Torino - Industry4Business', 'Industria 4.0, così finisce il \"diritto pesante\" del lavoro - CorCom']\n"
     ]
    }
   ],
   "source": [
    "# get docs titles\n",
    "titles = [doc['title'] for doc in docs]\n",
    "urls = [doc['url'] for doc in docs]\n",
    "print(titles[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental DBSCAN over small subset\n",
    "## TODO: check if noise is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Clusters##\n",
      "Noise:  ['Lavoro in Industry 4.0? Per i giovani è smart e condiviso', 'Smart Contract ed obbligazioni contrattuali: formalizzare il codice per assicurare la validità del contratto - Blockchain 4innovation', 'Impresa 4.0, Gentiloni: \"Il capitale umano è fondamentale\" - CorCom', 'La progettazione virtuale di Siemens al Forum Meccatronica di Torino - Industry4Business', 'Industria 4.0, così finisce il \"diritto pesante\" del lavoro - CorCom', 'Automotive | Internet 4 Things', 'Mercato IT, primo trimestre in corsa: la spesa supera i 7 miliardi - CorCom', 'Innovazione e competenze per l’automotive: inaugurata la Dallara Academy - Industry4Business', \"IoT Edge: un centro risorse per l'innovazione basata sui dati\", 'Smart Contract e blockchain - Pagina 5 di 5 - Blockchain 4innovation', 'Torino, è tempo di blockchain: partnership con Ifin Sistemi sulla formazione - Blockchain 4innovation', 'Industria 4.0, Italia e Germania insieme per la leadership europea - CorCom', 'MecSpe 2018, in mostra a Parma la via italiana a Industria 4.0', 'Industria 4.0, il governo punta a bonus per le Pmi - CorCom', \"Industry 4.0 (o industria 4.0): cos'è, notizie, normative, casi studio - I4T\", 'Impresa 4.0, la funzione HR è perno della trasformazione: ecco come', 'Wef: la robotica genera lavoro, +58 milioni di nuovi posti (ma solo se si investirà nelle e-skill) - CorCom', 'IoT e Big data per polizze auto “su misura”: accordo Octo-Rci bank and services', 'Nokia e AT&T insieme sull’IoT: industria 4.0 tra le priorità - Industry4Business', 'Le Pmi europee credono nelle opportunità della stampa 3D']\n",
      "DBSCAN finished.\n",
      "\n",
      "##Clusters##\n",
      "Cluster 0: ['Lavoro in Industry 4.0? Per i giovani è smart e condiviso', 'Impresa 4.0, la funzione HR è perno della trasformazione: ecco come']\n",
      "Cluster 1: ['Impresa 4.0, Gentiloni: \"Il capitale umano è fondamentale\" - CorCom', 'Automotive | Internet 4 Things', 'Mercato IT, primo trimestre in corsa: la spesa supera i 7 miliardi - CorCom', 'Innovazione e competenze per l’automotive: inaugurata la Dallara Academy - Industry4Business', 'Industria 4.0, Italia e Germania insieme per la leadership europea - CorCom', 'MecSpe 2018, in mostra a Parma la via italiana a Industria 4.0', 'Industria 4.0, il governo punta a bonus per le Pmi - CorCom', \"Industry 4.0 (o industria 4.0): cos'è, notizie, normative, casi studio - I4T\"]\n",
      "Noise:  ['Smart Contract ed obbligazioni contrattuali: formalizzare il codice per assicurare la validità del contratto - Blockchain 4innovation', 'La progettazione virtuale di Siemens al Forum Meccatronica di Torino - Industry4Business', 'Industria 4.0, così finisce il \"diritto pesante\" del lavoro - CorCom', \"IoT Edge: un centro risorse per l'innovazione basata sui dati\", 'Smart Contract e blockchain - Pagina 5 di 5 - Blockchain 4innovation', 'Torino, è tempo di blockchain: partnership con Ifin Sistemi sulla formazione - Blockchain 4innovation', 'Wef: la robotica genera lavoro, +58 milioni di nuovi posti (ma solo se si investirà nelle e-skill) - CorCom', 'IoT e Big data per polizze auto “su misura”: accordo Octo-Rci bank and services', 'Nokia e AT&T insieme sull’IoT: industria 4.0 tra le priorità - Industry4Business', 'Le Pmi europee credono nelle opportunità della stampa 3D']\n",
      "DBSCAN finished.\n",
      "\n",
      "##Clusters##\n",
      "Cluster 0: ['La progettazione virtuale di Siemens al Forum Meccatronica di Torino - Industry4Business', \"IoT Edge: un centro risorse per l'innovazione basata sui dati\", 'Smart Contract e blockchain - Pagina 5 di 5 - Blockchain 4innovation', 'Torino, è tempo di blockchain: partnership con Ifin Sistemi sulla formazione - Blockchain 4innovation', 'IoT e Big data per polizze auto “su misura”: accordo Octo-Rci bank and services', 'Nokia e AT&T insieme sull’IoT: industria 4.0 tra le priorità - Industry4Business', 'Le Pmi europee credono nelle opportunità della stampa 3D']\n",
      "Cluster 1: ['Industria 4.0, così finisce il \"diritto pesante\" del lavoro - CorCom', 'Wef: la robotica genera lavoro, +58 milioni di nuovi posti (ma solo se si investirà nelle e-skill) - CorCom']\n",
      "Noise:  ['Smart Contract ed obbligazioni contrattuali: formalizzare il codice per assicurare la validità del contratto - Blockchain 4innovation']\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset_length = 20\n",
    "# subset of docs vectors \n",
    "subset = inferred_vectors[:subset_length]\n",
    "subset_titles = titles[:subset_length]\n",
    "\n",
    "eps = 0.27\n",
    "eps_increment = 0.1\n",
    "# starting eps will be the sum of eps + eps_increment \n",
    "for i in range(3):\n",
    "    eps = eps + eps_increment\n",
    "    # decrease eps_increment a bit \n",
    "    #eps_increment = eps_increment - .02\n",
    "    db, c = perform_dbscan(eps = eps, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                        data = subset, verbose = True, titles = subset_titles, print_noise = True)\n",
    "\n",
    "    # let's try and find other clusters in the noise data, with higher eps\n",
    "    subset = [subset[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "    subset_titles = [subset_titles[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "    if subset is None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model Approach\n",
    "other idea, use entities as tags!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train corpus:  351\n",
      "Doc2Vec(\"live data\",dbow,d100,n5,mc2,t4)\n",
      "Doc2Vec(\"alpha=0.1-live data\",dm/m,d100,n5,w10,mc2,t4)\n",
      "Vocabulary created!\n",
      "Training Doc2Vec(\"live data\",dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 33.4 s, sys: 220 ms, total: 33.6 s\n",
      "Wall time: 11.5 s\n",
      "Training Doc2Vec(\"alpha=0.1-live data\",dm/m,d100,n5,w10,mc2,t4)\n",
      "CPU times: user 51.9 s, sys: 204 ms, total: 52.1 s\n",
      "Wall time: 15.9 s\n",
      "Models Saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import  gensim\n",
    "# get train corpus\n",
    "train_corpus = [gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(\n",
    "    d['title']+d['abstract']), [i]) for i, d in enumerate(docs) ]\n",
    "print(\"Length of train corpus: \",len(train_corpus))\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "\n",
    "# let's try training two models at once: Paragraph Vector - Distributed Memory (PV-DM), just like CBOW to W2V\n",
    "# and Paragraph Vector - Distributed Bag of Words (PV-DBOW), analogous to W2V Skip-gram\n",
    "epochs = 45\n",
    "vec_size = 100\n",
    "alpha = 0.10  # default= 0.030\n",
    "MODEL_NAME = \"Models_Live_Test/d2v_abstract&title\"\n",
    "\n",
    "models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=vec_size, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=epochs, workers=cores, comment='live data'),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, vector_size= vec_size, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs= epochs, workers=cores, alpha= alpha, comment='alpha=0.1-live data'),\n",
    "]\n",
    "\n",
    "# build our vocabulary of words (all the unique words encountered inside our corpus, needed for training)\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.build_vocab(train_corpus)\n",
    "print(\"Vocabulary created!\")\n",
    "\n",
    "# train the models on the given data!\n",
    "counter = 0\n",
    "for model in models:\n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(train_corpus, total_examples=len(train_corpus), epochs=model.epochs)\n",
    "    model.save(MODEL_NAME+str(counter)+'.model')\n",
    "    counter = counter + 1\n",
    "print(\"Models Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental DBSCAN over model vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"tag '351' not seen in training corpus/invalid\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-db2ce726b5e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubset_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdocvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# inferred vectors should result in the same vec as above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#inferred_vectors  = [model.infer_vector(doc.words) for i, doc in enumerate(train_corpus) if i<subset_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-db2ce726b5e4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubset_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdocvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# inferred vectors should result in the same vec as above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#inferred_vectors  = [model.infer_vector(doc.words) for i, doc in enumerate(train_corpus) if i<subset_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1529\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tag '%s' not seen in training corpus/invalid\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"tag '351' not seen in training corpus/invalid\""
     ]
    }
   ],
   "source": [
    "# load model\n",
    "modelname = 'Models_Live_Test/d2v_abstract&title0.model'\n",
    "model = Doc2Vec.load(modelname)\n",
    "\n",
    "subset_length = 25\n",
    "print(len(model.docvecs))\n",
    "docvecs = [vec for vec in model.docvecs]\n",
    "# inferred vectors should result in the same vec as above\n",
    "#inferred_vectors  = [model.infer_vector(doc.words) for i, doc in enumerate(train_corpus) if i<subset_length]\n",
    "\n",
    "# subset of docs vectors \n",
    "subset = docvecs[:subset_length]\n",
    "subset_titles = titles[:subset_length]\n",
    "\n",
    "eps = 0.35\n",
    "eps_increment = .15\n",
    "db = perform_dbscan(eps = eps, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = subset, verbose = True, titles = subset_titles)\n",
    "\n",
    "# let's try and find other clusters in the noise data, with higher eps\n",
    "noise_data = [subset[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "noise_titles = [subset_titles[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "\n",
    "db = perform_dbscan(eps = eps + eps_increment, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = noise_data, verbose = True, titles = noise_titles)\n",
    "\n",
    "# let's try and find other clusters in the noise data, with higher eps\n",
    "noise_data = [subset[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "noise_titles = [subset_titles[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "\n",
    "db = perform_dbscan(eps = eps + eps_increment + 0.1, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = noise_data, verbose = True, titles = noise_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize clusters over whole data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# load model\n",
    "MODEL_NAME = 'TestModels/d2v_TA_abstract&title0.model'\n",
    "MODEL_TWO = 'Models/d2v_TA_abstract&title0.model'\n",
    "#model = Doc2Vec.load(MODEL_NAME)\n",
    "model = Doc2Vec.load(MODEL_TWO)\n",
    "\n",
    "inferred_vectors = [model.infer_vector(doc) for doc in test_corpus]\n",
    "# loading dataset into Pandas DataFrame\n",
    "df = pd.DataFrame.from_records(inferred_vectors)\n",
    "\n",
    "# PCA is effected by scale so you need to scale the features in your data before applying PCA. \n",
    "vec_size = 100\n",
    "features = [i for i in range(vec_size)]\n",
    "\n",
    "x = df.loc[:, features].values # get features values\n",
    "\n",
    "# standardize data\n",
    "x = StandardScaler().fit_transform(x) # scale data (especially in case different measures are used)\n",
    "# build PCA model in 2D\n",
    "pca = PCA(n_components=2) # The new components are just the two main dimensions of variation.\n",
    "\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = principalDf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3/44.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "from scipy.spatial import distance\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3', api_key='FdMB4O6qCfciGDOnLvdQ')\n",
    "\n",
    "COMPONENT_ONE = \"principal component 1\"\n",
    "COMPONENT_TWO = \"principal component 2\"\n",
    "#centroids = kmeans.cluster_centers_\n",
    "titles = [dictionary['title'] for dictionary in docs]\n",
    "traces = []\n",
    "\n",
    "# each trace will represent a point (squeezed vector from higher dimensions),\n",
    "# and each point will have the title of the news assigned\n",
    "for i in range(len(finalDf)):\n",
    "    # assign a color to each point belonging to a specific cluster\n",
    "    # computing distance from centroid\n",
    "    #x = finalDf.loc[i:i, \"principal component 1\"]\n",
    "    #y = finalDf.loc[i:i, \"principal component 2\"]\n",
    "    x , y = finalDf.iat[i, 0], finalDf.iat[i, 1]\n",
    "    color = 'rgba(0, 0, 180, 0.8)'\n",
    "    \"\"\"\n",
    "    centroid_index = kmeans.predict([[x, y]])\n",
    "    closest_centroid = centroids[centroid_index]\n",
    "    #print(closest_centroid, centroids[0])\n",
    "    if np.array_equal(closest_centroid, [centroids[0]]):\n",
    "        color = 'blue'\n",
    "    elif np.array_equal(closest_centroid, [centroids[1]]):\n",
    "        color = 'pink'\n",
    "    elif np.array_equal(closest_centroid, [centroids[2]]):\n",
    "        color = 'yellow'\n",
    "    elif np.array_equal(closest_centroid, [centroids[3]]):\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    \"\"\"\n",
    "    \n",
    "    trace0 = go.Scatter(\n",
    "        x = [x], \n",
    "        y = [y],\n",
    "        mode = 'markers',\n",
    "            #name = 'blue markers',\n",
    "        marker = dict(\n",
    "            size = 7,\n",
    "            color = color,\n",
    "        ),\n",
    "        text = str(titles[i])\n",
    "    )\n",
    "    traces.append(trace0)\n",
    "\n",
    "# draw centroids\n",
    "\"\"\"\n",
    "c_colors = ['blue', 'pink', 'yellow', 'green', 'black']\n",
    "for i in range(len(centroids)):\n",
    "    c_trace = go.Scatter(\n",
    "        x = [centroids[i, 0]],\n",
    "        y = [centroids[i, 1]],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 9,\n",
    "            color = 'red',\n",
    "        ),\n",
    "        text = c_colors[i]\n",
    "    )\n",
    "    traces.append(c_trace)\n",
    "\"\"\"\n",
    "data = traces \n",
    "layout = dict(title = 'PCA Representantion of D2V on Title+Abstract',\n",
    "            hovermode= 'closest',\n",
    "            xaxis= dict(\n",
    "                title= 'first component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title= 'second component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            showlegend = False\n",
    "        )\n",
    "# Plot and embed in ipython notebook!\n",
    "    \n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename='live-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Cluster Entities\n",
    "Each cluster will be represented by a few meaningful entities, which summarize the cluster: \n",
    "these entities are chosen based on the most 'popular' among the documents which form a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# efficient way of getting most common elements in a list (O(n))\n",
    "def mostCommons(lst, n):\n",
    "    \"\"\"given a list, returns the n most common elements; in case of ties, it may not return the first occurence. \"\"\"\n",
    "    data = Counter(lst)\n",
    "    item_count_list = data.most_common(n)\n",
    "\n",
    "    return [item for (item, counter) in item_count_list]\n",
    "\n",
    "def getClusterEntites(cluster_docs = None, n_entities = 3):\n",
    "    \"\"\"given all documents belonging to a cluster (as a list of dictionaries, each dictionary \n",
    "    representing a doc with its attributes), returns the most common 'n_entities' in the cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get list of flattened_entities from documents\n",
    "    entities_field_name = 'flattened_entities'\n",
    "    # we're expecting flattened_entities as a list of strings\n",
    "    f_entities = [entity for doc in cluster_docs for entity in doc[entities_field_name]]\n",
    "    \n",
    "    # get the 'n_entities' most 'frequent' entity in the cluster\n",
    "    return mostCommons(f_entities, n_entities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tecnologia', 'industria_4.0', 'azienda', 'internet_delle_cose']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to use getClusterEntities\n",
    "\n",
    "## convert flattened_entites from string to list of strings\n",
    "for doc in docs:\n",
    "    if isinstance(doc['flattened_entities'], str):\n",
    "        doc['flattened_entities'] = doc['flattened_entities'].split()\n",
    "getClusterEntites(docs, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

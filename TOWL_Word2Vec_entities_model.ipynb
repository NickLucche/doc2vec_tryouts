{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec approach\n",
    "## Model will be trained on whole docs text, plus some 'reinforced' docs containing only entities; prediction phase will be tested on entities-only documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import json\n",
    "import random\n",
    "#import numpy as np\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import  gensim\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded correctly, type:  <class 'list'> 1569\n",
      "{'fonte_dati': ['trend_analisys'], 'id': 'https://www.punto-informatico.it/fujitsu-si-separa-da-pc-e-mobile/', 'ta_id': [5], 'title': 'Fujitsu si separa da PC e mobile', 'abstract': '   Roma – Per guadagnare in efficienza e tentare di rincorrere una posizione più appetibile sul mercato mobile e sul mercato del PC, per affrontare anni di profondi cambiamenti per entrambi i settori, Fujitsu  ha annunciato  lo spinoff delle due divisioni dedicate l’una a notebook e PC e l’altra agli smartphone. \\n Le due aziende, che nasceranno ufficialmente nel mese di febbraio del prossimo anno, consentiranno all’azienda “di chiarire le responsabilità nella gestione, di agevolare decisioni più rapide della dirigenza e di ottenere una maggiore efficienza”: aspetti fondamentali nel momento in cui la diffusione sempre più di massa e sempre più ubiqua di PC e smartphone “ha reso progressivamente sempre più difficile differenziarsi e ha reso sempre più serrata la competizione con i nuovi produttori globali”. \\n Fujitsu lascerà dunque che la propria divisione mobile viva di vita propria in Fujitsu Connected Technologies e tenti di farsi largo in uno scenario mobile estremamente  complesso  , con le sue stagnazioni, le sue conferme di lusso e le nuove esigenze dei mercati emergenti. \\n La divisione PC e notebook, che da febbraio farà capo a Fujitsu Client Computing Limited, affronterà una  conginutura  affatto positiva sperando nella ripresa. Nei mesi scorsi, caratterizzati da  sommovimenti  che  hanno interessato  l’assetto degli storici produttori giapponesi, circolava un’  indiscrezione  che tratteggiava un futuro comune per Fujitsu, Vaio e Toshiba: lo spinoff annunciato dall’azienda  potrebbe rappresentare  un primo passo in questa direzione. ', 'url': ['https://www.punto-informatico.it/fujitsu-si-separa-da-pc-e-mobile/'], 'website': ['punto-informatico.it'], 'timestamp': [1451308920000], 'publication_date': ['2015-12-28T13:22:00Z'], 'flattened_entities': ['azienda client computer_portatile fujitsu mercato roma smartphone spin-off_diritto telefonia_mobile toshiba'], 'result_entities': ['Roma', 'Mercato', 'Telefonia mobile', 'Fujitsu', 'Spin-off (diritto)', 'Computer portatile', 'Smartphone', 'Azienda', 'Client', 'Toshiba'], '_version_': 1613295373058572288}\n"
     ]
    }
   ],
   "source": [
    "## Load documents from json\n",
    "filename = 'clean_dataset.json'\n",
    "with open(filename, 'r') as out:\n",
    "        docs = json.load(out)\n",
    "        \n",
    "print(\"File loaded correctly, type: \", type(docs), len(docs))\n",
    "# we need a single string instead of a list in result_entities\n",
    "\"\"\"\n",
    "for doc in docs:\n",
    "    if isinstance(doc['result_entities'], list):\n",
    "        for word in doc['result_entities']:\n",
    "            word_sum = word_sum + word + ' '\n",
    "        doc['result_entities'] = word_sum\"\"\"\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train model\n",
    "## experiment: try to insert some entities-only docs in training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary created, number of known words:  11155\n",
      "Training Word2Vec(vocab=11155, size=100, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 292 ms, total: 4min 11s\n",
      "Wall time: 1min 7s\n",
      "Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# the effect I want to create by adding entities only docs is to 'pull' vectors towards meaningful words \n",
    "# in a doc, without losing the standard context they appear into\n",
    "\n",
    "train_corpus = [gensim.utils.simple_preprocess(doc['title'] + doc['abstract']) for doc in docs]\n",
    "# no need to pre-process entities, just make-sure they're lower-cased\n",
    "        \n",
    "train_corpus = train_corpus + [doc['result_entities'] for doc in docs]\n",
    "\n",
    "random.shuffle(train_corpus)\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "# sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "# negative (int, optional) – If > 0, negative sampling will be used, \n",
    "# the int for negative specifies how many “noise words” should be drawn (usually between 5-20).\n",
    "# every now and then we select a word and we ignore it by treating it as noise\n",
    "\n",
    "epochs = 30\n",
    "vec_size = 100\n",
    "entities_alpha = 0.10  \n",
    "abstract_alpha = 0.05 # here we have much more data\n",
    "MODEL_NAME = 'TestModels/w2v_entities+abstract_model.model'\n",
    "\n",
    "# let's introduce a higher min_count here, since we have a sufficient number of data\n",
    "\n",
    "# Skip-gram\n",
    "model = Word2Vec(size=vec_size, negative=5, hs=0, min_count=5, sample=0, \n",
    "        iter=epochs, workers=cores, sg = 1)\n",
    "\n",
    "\n",
    "# build our vocabulary of words (all the unique words encountered inside our corpus, needed for training)\n",
    "model.build_vocab(train_corpus)\n",
    "print(\"Vocabulary created, number of known words: \", len(model.wv.vocab))\n",
    "\n",
    "# train the models on the given data!\n",
    "\n",
    "print(\"Training %s\" % model)\n",
    "%time model.train(train_corpus, total_examples=len(train_corpus), epochs=model.iter)\n",
    "model.save(MODEL_NAME)\n",
    "\n",
    "print(\"Model Saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model \n",
    "MODEL_NAME = 'TestModels/w2v_entities+abstract_model.model'\n",
    "model = Word2Vec.load(MODEL_NAME)\n",
    "\n",
    "print(model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to represent a doc given its entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vector():\n",
    "    \"\"\"Given a list of entities, returns the vector representing the documents from which the entities \n",
    "    were extracted from, wrt a given W2V model.\"\"\"\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

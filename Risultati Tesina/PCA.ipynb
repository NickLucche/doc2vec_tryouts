{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "on same 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs: 293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/home/nick/anaconda3/bin/Tirocinio/doc2vec_tryouts/trend_analisys.json', 'r') as file:\n",
    "    docs = json.load(file)\n",
    "print(\"Length of docs:\",len(docs))\n",
    "\n",
    "# search for duplicates\n",
    "import utils\n",
    "docs = utils.delete_duplicates_from_list(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 293\n",
      "Doc2Vec(\"first model, 35 features\",dbow,d35,n5,mc2,s0.001,t3) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dbow,d50,n5,mc2,t4) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"dm=0, vec_size=100\",dbow,d100,n5,mc2,t4) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"dm=0, vec = 800, min_count=3\",dbow,d800,n5,mc3,t4) vocabulary built, with size: 4747\n",
      "iteration 0\n",
      "iteration 50\n",
      "iteration 100\n",
      "iteration 150\n",
      "iteration 200\n",
      "iteration 250\n",
      "Training Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dbow,d50,n5,mc2,t4)\n",
      "CPU times: user 2.2 s, sys: 24 ms, total: 2.22 s\n",
      "Wall time: 773 ms\n",
      "Training Doc2Vec(\"dm=0, vec_size=100\",dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 9.26 s, sys: 48 ms, total: 9.31 s\n",
      "Wall time: 3.14 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800, min_count=3\",dbow,d800,n5,mc3,t4)\n",
      "CPU times: user 35.5 s, sys: 232 ms, total: 35.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "# train the models \n",
    "train_corpus = [TaggedDocument(sp(doc['title']+doc['abstract']), [i]) for i, doc in enumerate(docs)]\n",
    "print(\"Number of docs:\",len(train_corpus))\n",
    "models = [\n",
    "    Doc2Vec(vector_size = 35,\n",
    "                alpha= 0.030,\n",
    "                min_alpha=0.00030,\n",
    "                min_count=2, # words that appear less than twice in the corpus are ignored\n",
    "                dm=0, comment='first model, 35 features') ,\n",
    "    Doc2Vec(dm=0, vector_size= 50, window=10, negative=5, hs=0, min_count=2, sample=0,\n",
    "            epochs= 10, workers=cores, alpha= 0.05, comment='alpha=0.05, dm=1, vec_size=40'),\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs= 40, workers=cores, comment='dm=0, vec_size=100'), \n",
    "    Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=3, sample=0,\n",
    "             epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800, min_count=3')\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.build_vocab(train_corpus)\n",
    "    print(model, \"vocabulary built, with size:\", len(model.wv.vocab))\n",
    "model = models[0]\n",
    "for epoch in range(300):\n",
    "    if(epoch%50==0):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "    model.train(train_corpus,\n",
    "                total_examples = model.corpus_count,\n",
    "                epochs = model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(train_corpus, total_examples=len(train_corpus), epochs=model.epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3_', api_key='4O71urldgOueVtcApOdX')\n",
    "descr = [m.comment for m in models]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualize_pca(model, subsample_length, titles):\n",
    "    # get list of doc_vecs\n",
    "    doc_vecs = [model[i] for i in range(len(model.docvecs))]\n",
    "    # apply pca\n",
    "    pcomponents = PCA(n_components = 2).fit_transform(doc_vecs)\n",
    "    \n",
    "    # now return plotly data over a subsample\n",
    "    colors = ['blue', 'red', 'yellow', 'green', 'brown']\n",
    "    traces = []\n",
    "    for i in range(subsample_length):\n",
    "        # give a color to certain topics\n",
    "        if 'Apple'.lower() in titles[i].lower():\n",
    "            color = colors[2]\n",
    "        elif 'Facebook'.lower() in titles[i].lower() or 'instagram' in titles[i].lower():\n",
    "            color = colors[0]\n",
    "        elif 'Marte'.lower() in titles[i].lower() or 'nasa' in titles[i].lower() or 'meteora' in titles[i].lower() or 'pianeta' in titles[i].lower() or 'Ufo' in titles[i]:\n",
    "            color = colors[1]\n",
    "        elif 'Samsung'.lower() in titles[i].lower() or 'galaxy' in titles[i].lower():\n",
    "            color = colors[3]\n",
    "        else:\n",
    "            color = colors[4]\n",
    "        trace = go.Scatter(\n",
    "            x = [pcomponents[i, 0]], # get first column\n",
    "            y = [pcomponents[i, 1]], # get second one\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                size = 7,\n",
    "                color = color,\n",
    "            ),\n",
    "            text = titles[i] \n",
    "        )\n",
    "        traces.append(trace)\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3_/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "titles = [doc['title'] for doc in docs]\n",
    "sub = 100\n",
    "for model in models:\n",
    "    trace = visualize_pca(model, 80, titles)\n",
    "    traces.append(trace)\n",
    "# visualize one at a time (plotly limitation)\n",
    "data = traces[2]\n",
    "layout = dict(title = 'PCA Representantion of DocVectors',\n",
    "        hovermode= 'closest',\n",
    "        xaxis= dict(\n",
    "            title= 'first component',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= 'second component',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        showlegend = False\n",
    "    )\n",
    "# Plot and embed in ipython notebook!\n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename='pca testing-good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3_/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = traces[0]\n",
    "layout = dict(title = 'PCA Representantion of DocVectors',\n",
    "        hovermode= 'closest',\n",
    "        xaxis= dict(\n",
    "            title= 'first component',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= 'second component',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        showlegend = False\n",
    "    )\n",
    "# Plot and embed in ipython notebook!\n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename='pca testing-bad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

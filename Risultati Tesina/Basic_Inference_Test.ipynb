{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs: 293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/home/nick/anaconda3/bin/Tirocinio/doc2vec_tryouts/trend_analisys.json', 'r') as file:\n",
    "    docs = json.load(file)\n",
    "print(\"Length of docs:\",len(docs))\n",
    "\n",
    "# search for duplicates\n",
    "import utils\n",
    "docs = utils.delete_duplicates_from_list(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare 3 different models: the first one I came across, the intermediate one, and the final model\n",
    "Then we'll see how each performs on the basic inference test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 293\n",
      "Doc2Vec(\"first model, 35 features\",dbow,d35,n5,mc2,s0.001,t3) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dbow,d50,n5,mc2,t4) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"dm=0, vec_size=100\",dbow,d100,n5,mc2,t4) vocabulary built, with size: 7507\n",
      "Doc2Vec(\"dm=0, vec = 800, min_count=3\",dbow,d800,n5,mc3,t4) vocabulary built, with size: 4747\n",
      "iteration 0\n",
      "iteration 50\n",
      "iteration 100\n",
      "iteration 150\n",
      "iteration 200\n",
      "iteration 250\n",
      "Training Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dbow,d50,n5,mc2,t4)\n",
      "CPU times: user 29.4 s, sys: 132 ms, total: 29.6 s\n",
      "Wall time: 10.3 s\n",
      "Training Doc2Vec(\"dm=0, vec_size=100\",dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 9.08 s, sys: 56 ms, total: 9.14 s\n",
      "Wall time: 3.07 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800, min_count=3\",dbow,d800,n5,mc3,t4)\n",
      "CPU times: user 34.2 s, sys: 208 ms, total: 34.4 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "# train the models \n",
    "train_corpus = [TaggedDocument(sp(doc['title']+doc['abstract']), [i]) for i, doc in enumerate(docs)]\n",
    "print(\"Number of docs:\",len(train_corpus))\n",
    "models = [\n",
    "    Doc2Vec(vector_size = 35,\n",
    "                alpha= 0.030,\n",
    "                min_alpha=0.00030,\n",
    "                min_count=2, # words that appear less than twice in the corpus are ignored\n",
    "                dm=0, comment='first model, 35 features') ,\n",
    "    Doc2Vec(dm=0, vector_size= 50, window=10, negative=5, hs=0, min_count=2, sample=0,\n",
    "            epochs= 150, workers=cores, alpha= 0.05, comment='alpha=0.05, dm=1, vec_size=40'),\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs= 40, workers=cores, comment='dm=0, vec_size=100'), \n",
    "    Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=3, sample=0,\n",
    "             epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800, min_count=3')\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.build_vocab(train_corpus)\n",
    "    print(model, \"vocabulary built, with size:\", len(model.wv.vocab))\n",
    "model = models[0]\n",
    "for epoch in range(300):\n",
    "    if(epoch%50==0):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "    model.train(train_corpus,\n",
    "                total_examples = model.corpus_count,\n",
    "                epochs = model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(train_corpus, total_examples=len(train_corpus), epochs=model.epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if the model is at least decent,\n",
    "# which means: is it able to at least recognize news/documents\n",
    "# it has seen in training?\n",
    "import random\n",
    "# Pick a random document from the train corpus and infer a vector from the model\n",
    "def basic_test(model, train_corpus, verbose=False, iterations = 0):\n",
    "    if iterations==0:\n",
    "        iterations = len(train_corpus)\n",
    "    correct = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "        inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "        similar_docs = model.docvecs.most_similar([inferred_vector], topn=3)\n",
    "        #print(doc_id, similar_docs)\n",
    "        if verbose:\n",
    "            titles = [doc['title'] for doc in docs]\n",
    "            # show the 3 most similar document titles\n",
    "            print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "            for doc_tag, similarity in similar_docs:\n",
    "                print(\"\\nSimilar Doc-->(doctag:{0},score:{1}):<<{2}>>\".format(doc_tag, similarity, titles[doc_tag]))\n",
    "        if doc_id == similar_docs[0][0]:\n",
    "            correct += 1\n",
    "        elif doc_id == similar_docs[1][0]:\n",
    "            correct_2 += 1\n",
    "        #elif doc_id == similar_docs[2][0]:\n",
    "        #    correct_3 += 1\n",
    "    # print success rate\n",
    "    print(\"Model\", model, \"had a success rate of:\",(correct * 100 / iterations))\n",
    "    print(\"Found the correct one in the second document {} out of {} times\".format(correct_2, (iterations-correct)))\n",
    "    return correct, correct_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Doc2Vec(\"first model, 35 features\",dbow,d35,n5,mc2,s0.001,t3) had a success rate of: 0.0\n",
      "Found the correct one in the second document 0 out of 293 times\n",
      "Model Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dbow,d50,n5,mc2,t4) had a success rate of: 69.28327645051195\n",
      "Found the correct one in the second document 82 out of 90 times\n",
      "Model Doc2Vec(\"dm=0, vec_size=100\",dbow,d100,n5,mc2,t4) had a success rate of: 70.30716723549489\n",
      "Found the correct one in the second document 83 out of 87 times\n",
      "Model Doc2Vec(\"dm=0, vec = 800, min_count=3\",dbow,d800,n5,mc3,t4) had a success rate of: 70.30716723549489\n",
      "Found the correct one in the second document 86 out of 87 times\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "k = len(train_corpus)\n",
    "for model in models:\n",
    "    c, c2 = basic_test(model, train_corpus, iterations=k)\n",
    "    correct.append((c * 100 / k, c2 * 100 / (k-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3_/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3_', api_key='4O71urldgOueVtcApOdX')\n",
    "descr = [m.comment for m in models]\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x = model_descr,\n",
    "    y = [x for (x, y) in correct],\n",
    "    name='Correct answers at first guess',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x = model_descr,\n",
    "    y = [y for (x, y) in correct],\n",
    "    name='Correct answers at second guess',\n",
    "    marker=dict(\n",
    "        color='rgb(155, 244, 66)',\n",
    "    )\n",
    "    \n",
    ")\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title = 'Basic Inference Test',\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=10,\n",
    "            color='rgb(107, 107, 107)',\n",
    "            \n",
    "        ),\n",
    "        tickangle = -45\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Inference accuracy (%)',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "   \n",
    "    barmode='group',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic inference testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 144 ms, total: 12.4 s\n",
      "Wall time: 4.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Doc2Vec(\"alpha=0.05, dm=1, vec_size=40\",dm/m,d45,n5,w5,mc2,s0.001,t4) had a success rate of: 68.9419795221843\n",
      "Found the correct one in the second document 88 out of 91 times\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202, 88)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Doc2Vec(vector_size= 45, min_count=2,\n",
    "            epochs= 20, workers=cores)\n",
    "m.build_vocab(train_corpus)\n",
    "%time m.train(train_corpus, total_examples=len(train_corpus), epochs=model.epochs)\n",
    "\n",
    "basic_test(m, train_corpus, iterations=len(train_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "this test doesn't really tell us much, unless the model is way out of sense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating W2V Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "# load pre-trained model\n",
    "model_name ='models/wiki_iter=5_algorithm=skipgram_window=10_size=300_neg-samples=10.m'\n",
    "\n",
    "model = Word2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec inference of doc as list of entities\n",
    "We will use these methods thoughout the notebook to infer a vector for a document, given a list of entities \n",
    "that represents a doc.\n",
    "TODO: WEIGHTED SUM BEFORE AVERAGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_of_vectors(vectors):\n",
    "    \"\"\"given a list of vectors, return the simplest mean of vectors.\"\"\"\n",
    "    ## vectors might be empty if no entity is recognized\n",
    "    if vectors == []:\n",
    "        return []\n",
    "    sum_vectors = np.zeros(np.shape(vectors[0]))\n",
    "    for vec in vectors:\n",
    "        sum_vectors = sum_vectors + vec\n",
    "    return sum_vectors/len(vectors)\n",
    "\n",
    "def infer_vector(entities, model, verbose = True):\n",
    "    \"\"\"Given a list of entities, returns the vector representing the document from which the entities \n",
    "    were extracted from, wrt a given W2V model.\n",
    "    \n",
    "    entities: list of entities, our way of representing a single document.\n",
    "    model: w2v model.\n",
    "    \"\"\"\n",
    "    unknown_words = 0\n",
    "    # get word vector of each entity; ignores word if the model does not know it\n",
    "    entities_vecs = []\n",
    "    for e in entities:\n",
    "        try:\n",
    "            # make sure to lower case each word!\n",
    "            entities_vecs.append(model[e.lower()])\n",
    "        except:\n",
    "            unknown_words += 1 # ignore unknown word\n",
    "    if unknown_words > 1 and verbose:\n",
    "        print(\"Number of unknown words: \", unknown_words, \", number of known words:\", (len(entities)-unknown_words))\n",
    "    return mean_of_vectors(entities_vecs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triples of docs test\n",
    "This test consists of presenting the model with triples of docs:\n",
    "e.g. (facebook_doc1, facebook_doc2, space_doc)\n",
    "the model correctly 'classifies' these triples if it's able to tell the difference between the 3rd and first two docs,\n",
    "while also recognizing the similarity between the first couple.\n",
    "\n",
    "Succeeding in this test means, later on, that whit a very high probability, the first 2 docs will be part of the same cluster, and the third one will be instead 'out' of that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of triples:  102\n",
      "Number of unknown words:  5 , number of known words: 7\n",
      "Number of unknown words:  3 , number of known words: 1\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  17 , number of known words: 14\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  11 , number of known words: 8\n",
      "Number of unknown words:  9 , number of known words: 13\n",
      "Number of unknown words:  5 , number of known words: 1\n",
      "Number of unknown words:  8 , number of known words: 8\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  29 , number of known words: 32\n",
      "Number of unknown words:  20 , number of known words: 37\n",
      "Number of unknown words:  16 , number of known words: 24\n",
      "Number of unknown words:  15 , number of known words: 9\n",
      "Number of unknown words:  5 , number of known words: 7\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  5 , number of known words: 3\n",
      "Number of unknown words:  7 , number of known words: 12\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  7 , number of known words: 12\n",
      "Number of unknown words:  26 , number of known words: 22\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  17 , number of known words: 14\n",
      "Number of unknown words:  16 , number of known words: 11\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  8 , number of known words: 11\n",
      "Unknown doc found\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  8 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 13\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 20\n",
      "Number of unknown words:  8 , number of known words: 6\n",
      "Number of unknown words:  18 , number of known words: 20\n",
      "Number of unknown words:  10 , number of known words: 10\n",
      "Number of unknown words:  2 , number of known words: 6\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  14 , number of known words: 7\n",
      "Number of unknown words:  4 , number of known words: 4\n",
      "Number of unknown words:  6 , number of known words: 17\n",
      "Number of unknown words:  5 , number of known words: 3\n",
      "Number of unknown words:  7 , number of known words: 12\n",
      "Number of unknown words:  25 , number of known words: 22\n",
      "Number of unknown words:  26 , number of known words: 22\n",
      "Number of unknown words:  5 , number of known words: 1\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  2 , number of known words: 7\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  14 , number of known words: 7\n",
      "Number of unknown words:  8 , number of known words: 6\n",
      "Number of unknown words:  27 , number of known words: 22\n",
      "Number of unknown words:  13 , number of known words: 13\n",
      "Number of unknown words:  14 , number of known words: 16\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  10 , number of known words: 7\n",
      "Number of unknown words:  3 , number of known words: 8\n",
      "Number of unknown words:  9 , number of known words: 13\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  14 , number of known words: 7\n",
      "Number of unknown words:  8 , number of known words: 15\n",
      "Number of unknown words:  10 , number of known words: 8\n",
      "Number of unknown words:  11 , number of known words: 14\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  8 , number of known words: 6\n",
      "Number of unknown words:  5 , number of known words: 7\n",
      "Number of unknown words:  10 , number of known words: 10\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  4 , number of known words: 9\n",
      "Number of unknown words:  2 , number of known words: 0\n",
      "Number of unknown words:  9 , number of known words: 13\n",
      "Unknown doc found\n",
      "Number of unknown words:  6 , number of known words: 6\n",
      "Number of unknown words:  5 , number of known words: 6\n",
      "Number of unknown words:  10 , number of known words: 7\n",
      "Number of unknown words:  30 , number of known words: 27\n",
      "Number of unknown words:  2 , number of known words: 3\n",
      "Number of unknown words:  20 , number of known words: 37\n",
      "Number of unknown words:  18 , number of known words: 34\n",
      "Number of unknown words:  16 , number of known words: 24\n",
      "Number of unknown words:  2 , number of known words: 0\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  6 , number of known words: 17\n",
      "Unknown doc found\n",
      "Number of unknown words:  5 , number of known words: 5\n",
      "Number of unknown words:  5 , number of known words: 6\n",
      "Number of unknown words:  16 , number of known words: 24\n",
      "Number of unknown words:  26 , number of known words: 22\n",
      "Number of unknown words:  5 , number of known words: 1\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  4 , number of known words: 9\n",
      "Number of unknown words:  16 , number of known words: 17\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  22 , number of known words: 25\n",
      "Number of unknown words:  10 , number of known words: 6\n",
      "Number of unknown words:  10 , number of known words: 6\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  25 , number of known words: 22\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  4 , number of known words: 9\n",
      "Number of unknown words:  10 , number of known words: 21\n",
      "Number of unknown words:  8 , number of known words: 11\n",
      "Number of unknown words:  5 , number of known words: 11\n",
      "Number of unknown words:  20 , number of known words: 5\n",
      "Number of unknown words:  5 , number of known words: 11\n",
      "Number of unknown words:  4 , number of known words: 16\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  6 , number of known words: 15\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 13\n",
      "Number of unknown words:  2 , number of known words: 7\n",
      "Number of unknown words:  17 , number of known words: 14\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  10 , number of known words: 5\n",
      "Number of unknown words:  10 , number of known words: 8\n",
      "Number of unknown words:  5 , number of known words: 5\n",
      "Number of unknown words:  16 , number of known words: 24\n",
      "Number of unknown words:  3 , number of known words: 2\n",
      "Number of unknown words:  14 , number of known words: 7\n",
      "Number of unknown words:  6 , number of known words: 17\n",
      "Number of unknown words:  16 , number of known words: 17\n",
      "Number of unknown words:  8 , number of known words: 15\n",
      "Number of unknown words:  11 , number of known words: 14\n",
      "Number of unknown words:  27 , number of known words: 22\n",
      "Number of unknown words:  7 , number of known words: 6\n",
      "Number of unknown words:  13 , number of known words: 13\n",
      "Number of unknown words:  11 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 3\n",
      "Number of unknown words:  20 , number of known words: 24\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  10 , number of known words: 5\n",
      "Number of unknown words:  8 , number of known words: 11\n",
      "Number of unknown words:  5 , number of known words: 11\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  4 , number of known words: 2\n",
      "Number of unknown words:  7 , number of known words: 7\n",
      "Number of unknown words:  20 , number of known words: 24\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  19 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 15\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  30 , number of known words: 27\n",
      "Number of unknown words:  3 , number of known words: 1\n",
      "Number of unknown words:  5 , number of known words: 7\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  10 , number of known words: 20\n",
      "Number of unknown words:  4 , number of known words: 9\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  3 , number of known words: 2\n",
      "Number of unknown words:  3 , number of known words: 11\n",
      "Number of unknown words:  3 , number of known words: 11\n",
      "Number of unknown words: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imacdev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/imacdev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 , number of known words: 20\n",
      "Number of unknown words:  29 , number of known words: 32\n",
      "Number of unknown words:  11 , number of known words: 14\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  8 , number of known words: 11\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  2 , number of known words: 9\n",
      "Number of unknown words:  10 , number of known words: 7\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 15\n",
      "Number of unknown words:  7 , number of known words: 6\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 21\n",
      "Number of unknown words:  5 , number of known words: 6\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  18 , number of known words: 20\n",
      "Number of unknown words:  7 , number of known words: 8\n",
      "Number of unknown words:  5 , number of known words: 9\n",
      "Number of unknown words:  18 , number of known words: 20\n",
      "Number of unknown words:  7 , number of known words: 7\n",
      "Number of unknown words:  10 , number of known words: 15\n",
      "Number of unknown words:  20 , number of known words: 24\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  3 , number of known words: 2\n",
      "Number of unknown words:  14 , number of known words: 9\n",
      "Number of unknown words:  18 , number of known words: 34\n",
      "Number of unknown words:  10 , number of known words: 20\n",
      "Number of unknown words:  18 , number of known words: 20\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  5 , number of known words: 3\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  4 , number of known words: 7\n",
      "Number of unknown words:  6 , number of known words: 7\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Unknown doc found\n",
      "Number of unknown words:  2 , number of known words: 7\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  7 , number of known words: 12\n",
      "Number of unknown words:  26 , number of known words: 22\n",
      "Number of unknown words:  2 , number of known words: 5\n",
      "Number of unknown words:  5 , number of known words: 6\n",
      "Number of unknown words:  3 , number of known words: 3\n",
      "Number of unknown words:  5 , number of known words: 4\n",
      "Number of unknown words:  6 , number of known words: 3\n",
      "Number of unknown words:  5 , number of known words: 6\n",
      "Number of unknown words:  20 , number of known words: 24\n",
      "Number of unknown words:  13 , number of known words: 18\n",
      "Number of unknown words:  30 , number of known words: 27\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  2 , number of known words: 0\n",
      "Number of unknown words:  14 , number of known words: 9\n",
      "Unknown doc found\n",
      "Number of unknown words:  13 , number of known words: 18\n",
      "Number of unknown words:  10 , number of known words: 20\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  5 , number of known words: 3\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 15\n",
      "Number of unknown words:  2 , number of known words: 3\n",
      "Number of unknown words:  23 , number of known words: 11\n",
      "Number of unknown words:  15 , number of known words: 9\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  2 , number of known words: 6\n",
      "Number of unknown words:  3 , number of known words: 2\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  17 , number of known words: 14\n",
      "Number of unknown words:  10 , number of known words: 6\n",
      "Number of unknown words:  5 , number of known words: 11\n",
      "Number of unknown words:  4 , number of known words: 16\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  9 , number of known words: 4\n",
      "Number of unknown words:  3 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 21\n",
      "Number of unknown words:  8 , number of known words: 8\n",
      "Number of unknown words:  10 , number of known words: 13\n",
      "Number of unknown words:  8 , number of known words: 6\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  11 , number of known words: 14\n",
      "Number of unknown words:  9 , number of known words: 9\n",
      "Number of unknown words:  5 , number of known words: 1\n",
      "Number of unknown words:  8 , number of known words: 8\n",
      "Number of unknown words:  4 , number of known words: 4\n",
      "Number of unknown words:  6 , number of known words: 6\n",
      "Number of unknown words:  10 , number of known words: 7\n",
      "Number of unknown words:  9 , number of known words: 5\n",
      "Number of unknown words:  13 , number of known words: 13\n",
      "Number of unknown words:  30 , number of known words: 27\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  3 , number of known words: 3\n",
      "Number of unknown words:  6 , number of known words: 8\n",
      "Number of unknown words:  6 , number of known words: 7\n",
      "Number of unknown words:  10 , number of known words: 6\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  16 , number of known words: 11\n",
      "Number of unknown words:  5 , number of known words: 9\n",
      "Number of unknown words:  9 , number of known words: 5\n",
      "Number of unknown words:  13 , number of known words: 13\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  13 , number of known words: 17\n",
      "Number of unknown words:  20 , number of known words: 5\n",
      "Number of unknown words:  4 , number of known words: 16\n",
      "Number of unknown words:  10 , number of known words: 20\n",
      "Number of unknown words:  11 , number of known words: 14\n",
      "Number of unknown words:  5 , number of known words: 10\n",
      "Number of unknown words:  14 , number of known words: 16\n",
      "Number of unknown words:  6 , number of known words: 17\n",
      "Number of unknown words:  2 , number of known words: 0\n",
      "Number of unknown words:  4 , number of known words: 2\n",
      "Number of unknown words:  9 , number of known words: 13\n",
      "Unknown doc found\n",
      "Number of unknown words:  10 , number of known words: 13\n",
      "Number of unknown words:  2 , number of known words: 7\n",
      "Number of unknown words:  10 , number of known words: 6\n",
      "Number of unknown words:  23 , number of known words: 11\n",
      "Number of unknown words:  7 , number of known words: 11\n",
      "Number of unknown words:  10 , number of known words: 15\n",
      "Number of unknown words:  4 , number of known words: 7\n",
      "Number of unknown words:  5 , number of known words: 4\n",
      "Number of unknown words:  9 , number of known words: 4\n",
      "Number of unknown words:  10 , number of known words: 21\n",
      "67 correct guesses over 102 triples\n",
      "65.68627450980392\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn.metrics.pairwise as sk\n",
    "\n",
    "# load test file\n",
    "# I also have another small set of docs from wikipedia, but they only contain abstract, not pre-processed entities\n",
    "filename = '3-docs-test/test.json'\n",
    "with open(filename, 'r') as test:\n",
    "    test_data = json.load(test)\n",
    "    \n",
    "similarity_threshold = 0.61 # when can we define two docs as similar? (empirical-obtained value)\n",
    "    \n",
    "# format: [... ,[{}, {}, {}], [ {}, {}, {}] ...   ]\n",
    "\n",
    "# let's try on flattened_entities too\n",
    "test_data = [(a['result_entities'], b['result_entities'], c['result_entities'])\n",
    "             for (a, b, c) in test_data]\n",
    "print(\"Number of triples: \", len(test_data))\n",
    "#print(test_data[:3])\n",
    "correct = 0\n",
    "for (a, b, c) in test_data: \n",
    "    # infer vector from each document\n",
    "    inferred_docs = [infer_vector(a, model), infer_vector(b, model), infer_vector(c, model)]\n",
    "    for ifd in inferred_docs:\n",
    "        if ifd == []:\n",
    "            print(\"Unknown doc found\")\n",
    "            continue\n",
    "            \n",
    "    # model.n_similarity does the same thing too\n",
    "    # we have to make sure we're passing it LOWER-CASE words\n",
    "    try:\n",
    "        if sk.cosine_similarity([inferred_docs[0]], [inferred_docs[1]]) >= similarity_threshold:\n",
    "            # docA and docB are guessed to be (correctly) similar\n",
    "            if sk.cosine_similarity([inferred_docs[0]], [inferred_docs[2]]) < similarity_threshold:\n",
    "                #docA and docC are not similar\n",
    "                if sk.cosine_similarity([inferred_docs[1]], [inferred_docs[2]]) < similarity_threshold:\n",
    "                        # guessed right\n",
    "                        correct += 1\n",
    "    except:\n",
    "        None\n",
    "print(\"%s correct guesses over %s triples\" %(correct, len(test_data)))\n",
    "percentage = correct*100 / len(test_data)\n",
    "print(str(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Online update approach\n",
    "re-train every time to make sure to have a representation for each word, even tho the model only sees this word in a small number of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght before update 733392\n",
      "CPU times: user 4.04 s, sys: 5.55 s, total: 9.59 s\n",
      "Wall time: 7.57 s\n",
      "CPU times: user 1min 39s, sys: 757 ms, total: 1min 40s\n",
      "Wall time: 58.3 s\n",
      "Lenght after update 733502\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess as sp\n",
    "import json\n",
    "\n",
    "filename = '3-docs-test/test.json'\n",
    "with open(filename, 'r') as test:\n",
    "    test_data = json.load(test)\n",
    "# re-train model using abstract\n",
    "print(\"Lenght before update\", len(model.wv.vocab))\n",
    "\n",
    "test_abstract = []\n",
    "for (a, b, c) in test_data:\n",
    "    test_abstract.append(sp(a['title'].lower()+a['abstract'].lower()))\n",
    "    test_abstract.append(sp(b['title'].lower()+b['abstract'].lower()))\n",
    "    test_abstract.append(sp(c['title'].lower()+c['abstract'].lower()))\n",
    "\n",
    "%time model.build_vocab(test_abstract, update=True)\n",
    "%time model.train(test_abstract, total_examples=model.corpus_count, total_words=model.corpus_total_words, epochs=3)\n",
    "\n",
    "print(\"Lenght after update\", len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imacdev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/imacdev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown doc found\n",
      "Unknown doc found\n",
      "Unknown doc found\n",
      "Unknown doc found\n",
      "Unknown doc found\n",
      "Unknown doc found\n",
      "38 correct guesses over 102 triples\n",
      "37.254901960784316\n"
     ]
    }
   ],
   "source": [
    "## Re-do test\n",
    "import json\n",
    "import sklearn.metrics.pairwise as sk\n",
    "\n",
    "# load test file\n",
    "# I also have another small set of docs from wikipedia, but they only contain abstract, not pre-processed entities\n",
    "filename = '3-docs-test/test.json'\n",
    "with open(filename, 'r') as test:\n",
    "    test_data = json.load(test)\n",
    "    \n",
    "similarity_threshold = 0.61 # when can we define two docs as similar? (empirical-obtained value)\n",
    "    \n",
    "# format: [... ,[{}, {}, {}], [ {}, {}, {}] ...   ]\n",
    "\n",
    "test_data = [(a['result_entities'], b['result_entities'], c['result_entities'])\n",
    "             for (a, b, c) in test_data]\n",
    "\n",
    "correct = 0\n",
    "for (a, b, c) in test_data: \n",
    "    # infer vector from each document\n",
    "    inferred_docs = [infer_vector(a, model, verbose=False), infer_vector(b, model, verbose = False), \n",
    "                     infer_vector(c, model, verbose = False)]\n",
    "    for ifd in inferred_docs:\n",
    "        if ifd == []:\n",
    "            print(\"Unknown doc found\")\n",
    "            continue\n",
    "            \n",
    "    try:\n",
    "        if sk.cosine_similarity([inferred_docs[0]], [inferred_docs[1]]) >= similarity_threshold:\n",
    "            # docA and docB are guessed to be (correctly) similar\n",
    "            if sk.cosine_similarity([inferred_docs[0]], [inferred_docs[2]]) < similarity_threshold:\n",
    "                #docA and docC are not similar\n",
    "                if sk.cosine_similarity([inferred_docs[1]], [inferred_docs[2]]) < similarity_threshold:\n",
    "                        # guessed right\n",
    "                        correct += 1\n",
    "    except:\n",
    "        None\n",
    "print(\"%s correct guesses over %s triples\" %(correct, len(test_data)))\n",
    "percentage = correct*100 / len(test_data)\n",
    "print(str(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

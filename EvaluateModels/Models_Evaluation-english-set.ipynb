{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different models-compare clustering results over eval. set\n",
    "TODO: try different eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Number of clusters: 3\n",
      "##Cluster length: ['20', '20', '20']\n",
      "### Doc length:  [10892, 5326, 4735, 3605, 7054, 1028, 1205, 10558, 4099, 2532, 5444, 3866, 1187, 3702, 5434, 261, 10860, 1859, 1325, 5784, 6009, 2788, 3228, 1736, 3098, 3075, 3638, 3608, 3619, 6182, 4331, 4516, 2265, 6123, 3943, 5139, 2874, 3922, 5734, 4247, 2320, 3093, 7587, 2811, 4230, 2806, 2622, 5009, 5855, 2910, 4416, 5706, 3281, 3273, 3973, 4828, 3675, 7436, 6775, 4819]\n"
     ]
    }
   ],
   "source": [
    "# load eval.set (duplicates free)\n",
    "import json\n",
    "filename = 'english_3_clusters.json'\n",
    "with open(filename, 'r') as file:\n",
    "    cdocs = json.load(file)\n",
    "print(\"#Number of clusters:\",len(cdocs))\n",
    "print(\"##Cluster length:\",[str(len(cluster)) for cluster in cdocs])\n",
    "print(\"### Doc length: \",[len(doc['headline']+doc['bodyText']) for cluster in cdocs for doc in cluster \n",
    "                          if not(doc['bodyText'] is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': {'id': 'google-news', 'name': 'Google News'}, 'author': 'info@hypebeast.com (HYPEBEAST), HYPEBEAST', 'title': \"Floyd Mayweather Jr. Announces New Year's Eve Fight with Tenshin Nasukawa\", 'description': 'In a surprising turn of events, the Rizin Fighting Federation has just held a press conference for a boxing matchup between Floyd Mayweather Jr. and Japanese kickboxer Tenshin Nasukawa. Although the two come from two different schools of fighting, both fighte…', 'url': 'http://feedproxy.google.com/~r/hypebeast/feed/~3/8AYgtu3E2WQ/', 'urlToImage': None, 'publishedAt': '2018-11-05T07:06:32Z', 'content': None}, {'source': {'id': 'the-hindu', 'name': 'The Hindu'}, 'author': 'The Hindu Net Desk', 'title': 'Adieu and Thank You, Kepler', 'description': 'On October 30, 2018, NASA announced that its Kepler space telescope has run out of fuel and that it will retire the spacecraft.\\nHere are a few things, Kepler taught us in its nine years of deep space', 'url': 'https://www.thehindu.com/sci-tech/science/adieu-and-thank-you-kepler/article25418100.ece', 'urlToImage': 'https://www.thehindu.com/sci-tech/science/3qygc0/article25382342.ece/ALTERNATES/LANDSCAPE_615/THJC-SPACEPLANETHUNTER', 'publishedAt': '2018-11-04T10:40:44Z', 'content': None}]\n"
     ]
    }
   ],
   "source": [
    "print([d for d in unwrapped_docs if d['content'] is None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title+abstract models\n",
    "## TODO: lower case text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 60\n",
      "[642, 844, 611, 490, 1759, 668, 710, 658, 441, 414, 695, 347, 798, 511, 961, 1805, 1240, 788, 907, 421, 201, 948, 481, 1093, 357, 1738, 904, 604, 45, 534, 479, 289, 524, 769, 623, 904, 251, 570, 595, 895, 656, 165, 196, 1058, 640, 200, 424, 471, 1150, 441, 750, 770, 609, 907, 1198, 710, 623, 574, 864, 521]\n",
      "Doc2Vec(\"dm=0, vec = 100\",dbow,d100,n5,mc2,t4) -VocabSize: 3093\n",
      "Doc2Vec(\"dm=0, vec = 500, lower eps\",dbow,d500,n5,mc2,t4) -VocabSize: 3093\n",
      "Doc2Vec(\"dm=0, vec = 800\",dbow,d800,n5,mc2,t4) -VocabSize: 3093\n",
      "Doc2Vec(\"dm=0, vec = 800, lower eps\",dbow,d800,n5,mc2,t4) -VocabSize: 3093\n",
      "Doc2Vec(\"dm=0, vec = 1000\",dbow,d1000,n5,mc2,t4) -VocabSize: 3093\n",
      "Doc2Vec(\"dm=0, vec = 800, min_count=3, epochs=20\",dbow,d800,n5,mc4,t4) -VocabSize: 1572\n",
      "Vocabulary created!\n",
      "Training Doc2Vec(\"dm=0, vec = 100\",dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 4.3 s, sys: 20 ms, total: 4.32 s\n",
      "Wall time: 1.54 s\n",
      "Training Doc2Vec(\"dm=0, vec = 500, lower eps\",dbow,d500,n5,mc2,t4)\n",
      "CPU times: user 8.53 s, sys: 36 ms, total: 8.56 s\n",
      "Wall time: 2.62 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800\",dbow,d800,n5,mc2,t4)\n",
      "CPU times: user 13.7 s, sys: 64 ms, total: 13.7 s\n",
      "Wall time: 4.03 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800, lower eps\",dbow,d800,n5,mc2,t4)\n",
      "CPU times: user 13.9 s, sys: 68 ms, total: 14 s\n",
      "Wall time: 4.09 s\n",
      "Training Doc2Vec(\"dm=0, vec = 1000\",dbow,d1000,n5,mc2,t4)\n",
      "CPU times: user 18.7 s, sys: 96 ms, total: 18.8 s\n",
      "Wall time: 5.81 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800, min_count=3, epochs=20\",dbow,d800,n5,mc4,t4)\n",
      "CPU times: user 7.9 s, sys: 76 ms, total: 7.97 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "# train different models\n",
    "from gensim.utils import simple_preprocess as sp\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing\n",
    "\n",
    "unwrapped_docs = [doc for cluster in cdocs for doc in cluster]\n",
    "\n",
    "import random\n",
    "random.shuffle(unwrapped_docs)\n",
    "# title + abstract models; here abstract is called 'content' (I got these articles from NewsAPI)\n",
    "train_corpus_ta = [ TaggedDocument(sp(doc['headline'] + doc['bodyText']) ,[i]) for i, doc in enumerate(unwrapped_docs)]\n",
    "print(\"Total number of documents:\",len(train_corpus_ta))\n",
    "#print(train_corpus_ta)\n",
    "print([len(doc.words) for doc in train_corpus_ta])\n",
    "epochs = 45\n",
    "vec_size = 100\n",
    "models = [\n",
    "    # dm = 0, simple SG, simpler model, most of the time efficient and accurate\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 100'),\n",
    "    Doc2Vec(dm=0, vector_size=500, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 500, lower eps'),\n",
    "    Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800'),\n",
    "    Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800, lower eps'),\n",
    "    Doc2Vec(dm=0, vector_size=1000, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 1000'),\n",
    "     Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=4, sample=0, \n",
    "            epochs=35, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800, min_count=3, epochs=20'),\n",
    "\n",
    "]\n",
    "\n",
    "# build our vocabulary of words (all the unique words encountered inside our corpus)\n",
    "for model in models:\n",
    "    model.build_vocab(train_corpus_ta)\n",
    "    print(model, \"-VocabSize:\", len(model.wv.vocab))\n",
    "print(\"Vocabulary created!\")\n",
    "\n",
    "# train the models on the given data!\n",
    "counter = 0\n",
    "for model in models:\n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(train_corpus_ta, total_examples=len(train_corpus_ta), epochs=model.epochs)\n",
    "    #model.save(MODEL_NAME+str(counter)+'.model')\n",
    "    counter = counter + 1\n",
    "#print(\"Models Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results occurences(correct guess, cluster index):  [(6, 1), (3, 3), (5, 11)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [30.0, 15.0, 25.0]\n",
      "Precision score: 100.0, Recall score: 23.333333333333332\n",
      "#Number of clusters found: 12, against number of pre-computed clusters: 3#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(6, 6), (3, 8), (9, 7)]\n",
      "Accuracy (Precision) over each cluster:  [85.71428571428571, 100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [30.0, 15.0, 45.0]\n",
      "Precision score: 95.23809523809524, Recall score: 30.0\n",
      "#Number of clusters found: 10, against number of pre-computed clusters: 3#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(7, 4), (3, 5), (7, 6)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [35.0, 15.0, 35.0]\n",
      "Precision score: 100.0, Recall score: 28.333333333333332\n",
      "#Number of clusters found: 12, against number of pre-computed clusters: 3#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(5, 9), (3, 7), (7, 10)]\n",
      "Accuracy (Precision) over each cluster:  [83.33333333333333, 100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [25.0, 15.0, 35.0]\n",
      "Precision score: 94.44444444444444, Recall score: 25.0\n",
      "#Number of clusters found: 13, against number of pre-computed clusters: 3#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(7, 4), (3, 5), (7, 6)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [35.0, 15.0, 35.0]\n",
      "Precision score: 100.0, Recall score: 28.333333333333332\n",
      "#Number of clusters found: 12, against number of pre-computed clusters: 3#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(12, 3), (4, 3), (9, 4)]\n",
      "Accuracy (Precision) over each cluster:  [75.0, 25.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [60.0, 20.0, 45.0]\n",
      "Precision score: 66.66666666666667, Recall score: 41.666666666666664\n",
      "#Number of clusters found: 12, against number of pre-computed clusters: 3#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import my_dbscan\n",
    "import model_evaluation as me\n",
    "import importlib\n",
    "importlib.reload(me)\n",
    "\n",
    "models_recall = []\n",
    "models_precision = []\n",
    "clusters_found = [] # keep clusters results, they're useful later on\n",
    "min_s = 2 # min_samples\n",
    "titles = [doc['headline'] for doc in unwrapped_docs]\n",
    "urls = [doc['headline'] for doc in unwrapped_docs] # I don't have url in the data-set\n",
    "    \n",
    "for k, model in enumerate(models):\n",
    "    # try different eps for some model\n",
    "    if k == 1 or k==3:\n",
    "        eps = 0.11\n",
    "        eps_increment = 0.13\n",
    "        min_s = 2\n",
    "    else:\n",
    "        eps = 0.27\n",
    "        eps_increment = 0.1\n",
    "        min_s = 2\n",
    "    # get list of document vectors\n",
    "    doc_vecs = [model.docvecs[j] for j in range(len(model.docvecs))]\n",
    "    \n",
    "    # apply dbscan clustering to these vectors\n",
    "    titles_clusters = my_dbscan.apply_dbscan(doc_vecs = doc_vecs, titles = titles, \n",
    "                                               urls = urls, subset_length = len(titles),\n",
    "                                                 eps = eps, eps_increment = eps_increment,\n",
    "                                               n_iterations = 3, verbose = False, min_samples = min_s)\n",
    "    # get clusters as list of titles\n",
    "    #titles_clusters = utils.getDocTitleFromUrl(unwrapped_docs, urls_cluster_list)\n",
    "    clusters_found.append(titles_clusters)\n",
    "    #data = utils.plot_clusters(titles_clusters)\n",
    "    \n",
    "    # evaluate clustering\n",
    "    expected_clusters = []\n",
    "    for docs in cdocs:\n",
    "        expected_clusters.append([doc['headline'] for doc in docs])\n",
    "    precision, recall = me.compute_clustering_accuracy(titles_clusters, expected_clusters)\n",
    "    print('Precision score: %s, Recall score: %s'%(precision, recall))\n",
    "    \n",
    "    models_precision.append(precision)\n",
    "    models_recall.append(recall)\n",
    "    # last check: we want to penalize models that simply cluster all docs together (that's not a valid result)\n",
    "    # that's way we have precision score\n",
    "    print(\"#Number of clusters found: {0}, against number of pre-computed clusters: {1}#\\n\".format(\n",
    "        len(titles_clusters), len(cdocs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Could the Earth lose its atmosphere as Mars once did?', 'Don’t let bacteria-laden humans contaminate Mars']\n",
      "['North Korea threat remains despite Trump summit, says Japan', 'Japan defence ministry seeks record budget over North Korea threat']\n",
      "['Take-up of MMR vaccine falls for fourth year in a row in England', \"Rubella's elimination from Australia 'shows vaccinations work'\"]\n",
      "['North Korea set to allow inspectors into nuclear test site', \"North Korea 'destroys' nuclear test site as world's media watches\"]\n",
      "['Over-65s to be given more effective flu vaccine', 'NHS denies flu vaccine shortage amid complaints over delays']\n",
      "['The most likely cradles for life inside our solar system', 'Nasa Mars rover finds organic matter in ancient lake bed']\n",
      "['Scientists call for ‘mega-mission’ to find ancient life on Mars', 'Spacewatch: Martian rocks on Earth a step nearer as UK builds red planet rover']\n",
      "['China: outcry over sale of 250,000 faulty vaccines prompts investigation', 'Beaten, terrified and disappeared: China cracks down on faulty vaccine outcry', \"'They are devils': China's parents demand answers over vaccine scandal\"]\n",
      "['Teenage boys to be vaccinated against cancer-causing HPV', 'Australia on track to wipe out cervical cancer within 20 years']\n",
      "['Mars to track blood moon in double celestial treat on Friday', 'Nasa mission to map Mars interior will launch this weekend', 'Spacewatch: Can Mars rover beat the dust to trundle on again?', 'Ethiopia deploys hidden rabies vaccine in bid to protect endangered wolf', \"Orange snow transforms eastern Europe into 'Mars'\", \"Planet of the apis: Nasa develops plan to launch 'Marsbees'\"]\n",
      "['Pompeo backs away from North Korea denuclearisation timeline', 'North Korea is still developing nuclear weapons, says IAEA', \"Koreas' Kim and Moon to meet again as Trump nuclear agenda sidelined\", 'Mike Pompeo to visit North Korea this week for nuclear talks', 'Trump orders Pompeo to delay nuclear North Korea talks due to lack of progress', 'South Korea and US resume military drills ahead of nuclear talks', 'US may resume war games as North Korea negotiations stall']\n",
      "[\"MPs 'shocked' by low flu vaccine rates among social care staff\", 'Yes, you should have a flu jab']\n",
      "['Congo turmoil means Ebola vaccinators will need armed escorts, experts warn', 'DRC: experimental Ebola vaccine to be administered in Mbandaka']\n"
     ]
    }
   ],
   "source": [
    "for cluster in clusters_found[3]:\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "Here, you can clearly see how important the clustering alg. is for obtaining good results: the data-set is (objectively) okay, it has more than enough words, and each model gets a pretty high Precision score, which means that (almost) every document that is put together rightfully belongs to the same cluster, as you can see in the clusters; the 'problem' is that we're splitting clusters too much, finding meaningful, but somewhat unecessary sub-clusters, very specific to a single topic, which is not a bad thing.. it means that by tweaking that 'eps' we can get pretty different results.. is there a way to choose the eps value automatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~D4nt3_/0 or inside your plot.ly account where it is named 'aa'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3_/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "# finally, call eps-estimate function\n",
    "title_dist_tuples = utils.choose_eps(2, doc_vecs, titles)\n",
    "data = utils.visualize_eps_graph(title_dist_tuples=title_dist_tuples)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3_', api_key='4O71urldgOueVtcApOdX')\n",
    "py.iplot(data, filename='aa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3_/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "# using my api-key\n",
    "tls.set_credentials_file(username='D4nt3_', api_key='4O71urldgOueVtcApOdX')\n",
    "graph_name = 'model_eval_result_3_cl'\n",
    "\n",
    "model_descr = [model.comment for model in models]\n",
    "# plot test-accuracy results, plus silhoutte scores (times 100, since all the values are in between 0-1)\n",
    "trace0 = go.Bar(\n",
    "    x = model_descr,\n",
    "    y = models_precision,\n",
    "    name='Precision',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x = model_descr,\n",
    "    y = models_recall,\n",
    "    name='Recall',\n",
    "    marker=dict(\n",
    "        color='rgb(155, 244, 66)',\n",
    "    )\n",
    "    \n",
    ")\n",
    "# precision, recall, silhoutte\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title = 'Clustering Accuracy Results',\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=10,\n",
    "            color='rgb(107, 107, 107)',\n",
    "            \n",
    "        ),\n",
    "        tickangle = -45\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Clustering accuracy (%)',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "   \n",
    "    barmode='group',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename=graph_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhoutte score\n",
    "Silhouette coefficient combines ideas of both cohesion and separation, \n",
    "but for individual points, as well as clusters and \n",
    "clusterings; the Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample.\n",
    "The Silhoutte score is merely the average of each silhoutte coefficient, computed over each sample.\n",
    "It's a measure of the goodness of clustering, by assuming the fact that a cluster X is defined good if both every sample inside it is close to each other, and far from any other relatively-near cluster Y.\n",
    "This is not necessarily true for every shape of cluster.\n",
    "\n",
    "    The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-571257437e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls_cluster_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# keep cluster id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'url'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "s_scores = []\n",
    "for model in models:\n",
    "    # get clusters for each model\n",
    "    doc_vecs = [model.docvecs[j] for j in range(len(model.docvecs))]\n",
    "    titles = [doc['title'] for doc in unwrapped_docs]\n",
    "    urls = [doc['url'] for doc in unwrapped_docs]\n",
    "    # apply dbscan clustering to these vectors\n",
    "    urls_cluster_list = my_dbscan.apply_dbscan(doc_vecs = doc_vecs, titles = titles, \n",
    "                                               urls = urls, subset_length = len(titles),\n",
    "                                                 eps = 0.27, eps_increment = 0.1, n_iterations = 3, verbose = False)\n",
    "    \n",
    "    # get cluster labels, mantaining original docs ordering\n",
    "    labels = []\n",
    "    for doc in unwrapped_docs:\n",
    "        noise = True\n",
    "        for i, url_list in enumerate(urls_cluster_list):\n",
    "            if(doc['url'] in url_list):\n",
    "                labels.append(i) # keep cluster id\n",
    "                noise = False\n",
    "        if noise:\n",
    "            labels.append(-1)\n",
    "    # make sure they have the same size\n",
    "    assert len(labels) == len(doc_vecs)\n",
    "    ss = silhouette_score(doc_vecs, labels , metric='cosine')\n",
    "    s_scores.append(ss)\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions: \n",
    "A really low silhoutte score helps us identify models that tend to have very few cluster, hence not really recognizing differences between docs. This is fundamental, since test rules used so far prevent us from recognizing these kinds of models.\n",
    "Since silhoutte score is an average of silhoutte coefficients, smaller changes of values here may mean greater differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

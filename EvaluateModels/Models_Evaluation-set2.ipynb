{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different models-compare clustering results over eval. set\n",
    "TODO: try different eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters 2\n"
     ]
    }
   ],
   "source": [
    "# load eval.set (duplicates free)\n",
    "import json\n",
    "filename = 'blockchain_whatsapp_noise.json'\n",
    "with open(filename, 'r') as file:\n",
    "    cdocs = json.load(file)\n",
    "print(\"Number of clusters\", len(cdocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title+abstract models\n",
    "## TODO: lower case text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 35, length of each doc [3266, 2972, 4603, 1037, 4639, 2605, 2256, 265, 6692, 2569, 402, 3823, 7249, 3241, 1697, 2851, 5056, 1209, 738, 1389, 1357, 1688, 224, 1090, 897, 986, 1193, 1597, 945, 224, 1271, 1222, 714, 715, 1769]\n",
      "Model loaded\n",
      "Doc2Vec(\"dm=0, vec = 100\",dbow,d100,n5,mc2,t4)\n",
      "Doc2Vec(\"dm=0, vec = 500, lower eps\",dbow,d500,n5,mc2,t4)\n",
      "Doc2Vec(\"dm=0, vec = 800\",dbow,d800,n5,mc2,t4)\n",
      "Doc2Vec(\"dm=0, vec = 1000\",dbow,d1000,n5,mc2,t4)\n",
      "Doc2Vec(\"dm=1, vec=100, alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "Doc2Vec(\"dm=1, vec=150, alpha=0.5, hs=1\",dm/m,d150,n5,w5,mc2,s0.001,t4)\n",
      "Doc2Vec(\"dm=1, vec=500, lower eps, min_pts=3\",dm/m,d500,n5,w10,mc2,t4)\n",
      "Doc2Vec(\"dm=1, vec=500, alpha=.05\",dm/m,d500,n5,w10,mc2,t4)\n",
      "Vocabulary created!\n",
      "Training Doc2Vec(\"dm=0, vec = 100\",dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 1.12 s, sys: 32 ms, total: 1.16 s\n",
      "Wall time: 1.85 s\n",
      "Training Doc2Vec(\"dm=0, vec = 500, lower eps\",dbow,d500,n5,mc2,t4)\n",
      "CPU times: user 1.98 s, sys: 24 ms, total: 2.01 s\n",
      "Wall time: 2.86 s\n",
      "Training Doc2Vec(\"dm=0, vec = 800\",dbow,d800,n5,mc2,t4)\n",
      "CPU times: user 2.3 s, sys: 8 ms, total: 2.31 s\n",
      "Wall time: 2.9 s\n",
      "Training Doc2Vec(\"dm=0, vec = 1000\",dbow,d1000,n5,mc2,t4)\n",
      "CPU times: user 2.76 s, sys: 12 ms, total: 2.78 s\n",
      "Wall time: 3.28 s\n",
      "Training Doc2Vec(\"dm=1, vec=100, alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "CPU times: user 1.88 s, sys: 16 ms, total: 1.9 s\n",
      "Wall time: 2.55 s\n",
      "Training Doc2Vec(\"dm=1, vec=150, alpha=0.5, hs=1\",dm/m,d150,n5,w5,mc2,s0.001,t4)\n",
      "CPU times: user 1.2 s, sys: 36 ms, total: 1.24 s\n",
      "Wall time: 1.49 s\n",
      "Training Doc2Vec(\"dm=1, vec=500, lower eps, min_pts=3\",dm/m,d500,n5,w10,mc2,t4)\n",
      "CPU times: user 3.34 s, sys: 28 ms, total: 3.37 s\n",
      "Wall time: 4.21 s\n",
      "Training Doc2Vec(\"dm=1, vec=500, alpha=.05\",dm/m,d500,n5,w10,mc2,t4)\n",
      "CPU times: user 3.31 s, sys: 32 ms, total: 3.34 s\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "# train different models\n",
    "from gensim.utils import simple_preprocess as sp\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing\n",
    "\n",
    "unwrapped_docs = [doc for cluster in cdocs for doc in cluster]\n",
    "print(\"Number of docs: %s, length of each doc %s\" %(len(unwrapped_docs), [len(doc['abstract'])for doc in unwrapped_docs]))\n",
    "# title + abstract models\n",
    "train_corpus_ta = [ TaggedDocument(sp(doc['title'] + doc['abstract']) ,[i]) for i, doc in enumerate(unwrapped_docs)]\n",
    "epochs = 45\n",
    "vec_size = 100\n",
    "models = [\n",
    "    # dm = 0, simple SG, simpler model, most of the time efficient and accurate\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 100'),\n",
    "    Doc2Vec(dm=0, vector_size=500, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 500, lower eps'),\n",
    "    Doc2Vec(dm=0, vector_size=800, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 800'),\n",
    "    Doc2Vec(dm=0, vector_size=1000, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=45, workers=multiprocessing.cpu_count(), comment='dm=0, vec = 1000'),\n",
    "    # dm = 1, CBOW equivalent \n",
    "    Doc2Vec(dm=1, vector_size= 100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs = epochs, workers=multiprocessing.cpu_count(), alpha= 0.05, comment='dm=1, vec=100, alpha=0.05'),\n",
    "    Doc2Vec(dm=1, vector_size= 150, min_count=2,epochs = epochs, \n",
    "            workers=multiprocessing.cpu_count(), alpha= 0.5, comment='dm=1, vec=150, alpha=0.5, hs=1'),\n",
    "    Doc2Vec(dm=1, vector_size= 500, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs = epochs, workers=multiprocessing.cpu_count(), alpha= 0.05, comment='dm=1, vec=500, lower eps, min_pts=3'),\n",
    "    Doc2Vec(dm=1, vector_size= 500, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs = epochs, workers=multiprocessing.cpu_count(), alpha= 0.05, comment='dm=1, vec=500, alpha=.05')\n",
    "]\n",
    "# also evaluate result on currently used model\n",
    "loaded_model = Doc2Vec.load('/home/nick/anaconda3/bin/Tirocinio/doc2vec_tryouts/Models_Live_Test/d2v_abstract&title0.model')\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# build our vocabulary of words (all the unique words encountered inside our corpus)\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.build_vocab(train_corpus_ta)\n",
    "print(\"Vocabulary created!\")\n",
    "\n",
    "# train the models on the given data!\n",
    "counter = 0\n",
    "for model in models:\n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(train_corpus_ta, total_examples=len(train_corpus_ta), epochs=model.epochs)\n",
    "    #model.save(MODEL_NAME+str(counter)+'.model')\n",
    "    counter = counter + 1\n",
    "#print(\"Models Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results occurences(correct guess, cluster index):  [(3, 0), (7, 2)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [20.0, 35.0]\n",
      "Precision score: 100.0, Recall score: 27.5\n",
      "#Number of clusters found: 6, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(3, 0), (17, 1)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [20.0, 85.0]\n",
      "Precision score: 100.0, Recall score: 52.5\n",
      "#Number of clusters found: 6, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(4, 3), (18, 1)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [26.666666666666668, 90.0]\n",
      "Precision score: 100.0, Recall score: 58.333333333333336\n",
      "#Number of clusters found: 6, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(7, 2), (18, 0)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 85.71428571428571]\n",
      "Accuracy (Recall) over each cluster:  [46.666666666666664, 90.0]\n",
      "Precision score: 92.85714285714286, Recall score: 68.33333333333333\n",
      "#Number of clusters found: 4, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(4, 4), (9, 6)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [26.666666666666668, 45.0]\n",
      "Precision score: 100.0, Recall score: 35.833333333333336\n",
      "#Number of clusters found: 8, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(6, 1), (12, 2)]\n",
      "Accuracy (Precision) over each cluster:  [50.0, 70.58823529411765]\n",
      "Accuracy (Recall) over each cluster:  [40.0, 60.0]\n",
      "Precision score: 60.294117647058826, Recall score: 50.0\n",
      "#Number of clusters found: 3, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(3, 3), (14, 4)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [20.0, 70.0]\n",
      "Precision score: 100.0, Recall score: 45.0\n",
      "#Number of clusters found: 6, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(3, 7), (5, 8)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [20.0, 25.0]\n",
      "Precision score: 100.0, Recall score: 22.5\n",
      "#Number of clusters found: 10, against number of pre-computed clusters: 2#\n",
      "\n",
      "Results occurences(correct guess, cluster index):  [(2, 2), (4, 4)]\n",
      "Accuracy (Precision) over each cluster:  [100.0, 100.0]\n",
      "Accuracy (Recall) over each cluster:  [13.333333333333334, 20.0]\n",
      "Precision score: 100.0, Recall score: 16.666666666666668\n",
      "#Number of clusters found: 5, against number of pre-computed clusters: 2#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import my_dbscan\n",
    "import model_evaluation as me\n",
    "import importlib\n",
    "importlib.reload(me)\n",
    "\n",
    "models_recall = []\n",
    "models_precision = []\n",
    "clusters_found = [] # keep clusters results, they're useful later on\n",
    "min_s = 2 # min_samples\n",
    "for k, model in enumerate(models):\n",
    "    # try different eps for some model\n",
    "    if k == 1:\n",
    "        eps = 0.11\n",
    "        eps_increment = 0.13\n",
    "        min_s = 2\n",
    "    elif k==6:\n",
    "        eps = 0.11\n",
    "        eps_increment = 0.13\n",
    "        min_s = 3\n",
    "    else:\n",
    "        eps = 0.11\n",
    "        eps_increment = 0.13\n",
    "        min_s = 2\n",
    "    # get list of document vectors\n",
    "    doc_vecs = [model.docvecs[j] for j in range(len(model.docvecs))]\n",
    "    titles = [doc['title'] for doc in unwrapped_docs]\n",
    "    urls = [doc['url'] for doc in unwrapped_docs]\n",
    "    # apply dbscan clustering to these vectors\n",
    "    urls_cluster_list = my_dbscan.apply_dbscan(doc_vecs = doc_vecs, titles = titles, \n",
    "                                               urls = urls, subset_length = len(titles),\n",
    "                                                 eps = eps, eps_increment = eps_increment,\n",
    "                                               n_iterations = 3, verbose = False, min_samples = min_s)\n",
    "    # get clusters as list of titles\n",
    "    titles_clusters = utils.getDocTitleFromUrl(unwrapped_docs, urls_cluster_list)\n",
    "    clusters_found.append(titles_clusters)\n",
    "    #data = utils.plot_clusters(titles_clusters)\n",
    "    \n",
    "    # evaluate clustering\n",
    "    expected_clusters = []\n",
    "    for docs in cdocs:\n",
    "        expected_clusters.append([doc['title'] for doc in docs])\n",
    "    precision, recall = me.compute_clustering_accuracy(titles_clusters, expected_clusters)\n",
    "    print('Precision score: %s, Recall score: %s'%(precision, recall))\n",
    "    \n",
    "    models_precision.append(precision)\n",
    "    models_recall.append(recall)\n",
    "    # last check: we want to penalize models that simply cluster all docs together (that's not a valid result)\n",
    "    # that's way we have precision score\n",
    "    print(\"#Number of clusters found: {0}, against number of pre-computed clusters: {1}#\\n\".format(\n",
    "        len(urls_cluster_list), len(cdocs)))\n",
    "\n",
    "## loaded model\n",
    "inferred_vecs = [loaded_model.infer_vector(sp(doc['title']+doc['abstract'])) for doc in unwrapped_docs]\n",
    "urls_cluster_list = my_dbscan.apply_dbscan(doc_vecs = inferred_vecs, titles = titles, \n",
    "                                               urls = urls, subset_length = len(titles),\n",
    "                                                 eps = eps, eps_increment = eps_increment, n_iterations = 3, verbose = False)\n",
    "titles_clusters = utils.getDocTitleFromUrl(unwrapped_docs, urls_cluster_list)\n",
    "clusters_found.append(titles_clusters)\n",
    "# evaluate clustering\n",
    "expected_clusters = []\n",
    "for docs in cdocs:\n",
    "    expected_clusters.append([doc['title'] for doc in docs])\n",
    "precision, recall = me.compute_clustering_accuracy(titles_clusters, expected_clusters)\n",
    "print('Precision score: %s, Recall score: %s'%(precision, recall))\n",
    "models_precision.append(precision)\n",
    "models_recall.append(recall)\n",
    "print(\"#Number of clusters found: {0}, against number of pre-computed clusters: {1}#\\n\".format(\n",
    "    len(urls_cluster_list), len(cdocs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WhatsApp monetizza con le Aziende, profili Business parzialmente a pagamento - Corriere.it', 'WhatsApp a pagamento dal 13 gennaio 2018: l’ennesima bufala - Corriere.it', 'WhatsApp, presto potremo fare pagamenti via chat - Corriere.it', 'Facebook vuole mettere la pubblicità su WhatsApp - Corriere.it', 'WhatsApp a pagamento, ma solo per le aziende lente a rispondere - Wired']\n",
      "['WhatsApp, cancellare messaggi inviati è più facile: oltre un’ora di tempo - Corriere.it', 'WhatsApp, i messaggi cancellati si possono recuperare - Corriere.it']\n",
      "['Ecco perché WhatsApp non funzionava (e se fosse colpa della Juve?) - Corriere.it', 'WhatsApp, mandi il messaggio e ti penti? Presto potremo ripensarci (per 5 minuti) e cancellarlo - Corriere.it']\n",
      "[\"200 nuovi laureati per IBM: l'innovazione ha bisogno anche della Blockchain - Blockchain 4innovation\", 'Deloitte-Dnv GL, nasce la certificazione blockchain: “È solo l’inizio” - Blockchain 4innovation']\n",
      "['Arriva SIAChain la piattaforma Blockchain di SIA - Blockchain 4innovation', 'L’accordo Hong Kong-Singapore per l’utilizzo della Blockchain - Blockchain 4innovation', 'Smart Contract e blockchain - Pagina 4 di 5 - Blockchain 4innovation', 'Smart Contract e blockchain - Blockchain 4innovation']\n",
      "['Arriva Notarchain: la Blockchain tutta italiana - Blockchain 4innovation', 'Abbanoa punta sulla blockchain per certificare la lettura dei contatori - Blockchain 4innovation']\n",
      "['Su WhatsApp arrivano i pagamenti tra utenti: si inizia in India - Corriere.it', 'L’app italiana per acquistare un’auto via WhatsApp - Corriere.it', 'WhatsApp può svelare quando dormi e con chi chatti - Corriere.it', 'Facebook: Tinder nel mirino, novità di Instagram e Whatsapp - Corriere.it', 'WhatsApp rivoluziona i gruppi: le 3 novità - Corriere.it', \"Chat di gruppo su WhatsApp, c’è un buco per entrare. Ma l'app minimizza - Corriere.it\", 'Facebook compra WhatsApp, operazione record da 14 miliardi di euro - Corriere.it', \"Arriva la spunta verde su WhatsApp ecco cos'è e a cosa serve - Corriere.it\", 'WhatsApp limita i messaggi inoltrati dopo il caos in India e Myanmar - Corriere.it']\n",
      "['Adolescenti: meglio WhatsApp che dal vivo', 'WhatsApp cambia il rapporto tra scuola e genitori']\n"
     ]
    }
   ],
   "source": [
    "for cluster in clusters_found[4]:\n",
    "    print(cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3/90.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "# using my api-key\n",
    "tls.set_credentials_file(username='D4nt3', api_key='FdMB4O6qCfciGDOnLvdQ')\n",
    "graph_name = 'model_eval_results_2'\n",
    "\n",
    "model_descr = [model.comment for model in models]\n",
    "# plot test-accuracy results, plus silhoutte scores (times 100, since all the values are in between 0-1)\n",
    "trace0 = go.Bar(\n",
    "    x = model_descr + ['loaded model'],\n",
    "    y = models_precision,\n",
    "    name='Precision',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x = model_descr + ['loaded model'],\n",
    "    y = [s*100 for s in s_scores] + [0],\n",
    "    name='Silhoutte score',\n",
    "    marker=dict(\n",
    "        color='rgb(204,50,100)',\n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x = model_descr + ['loaded model'],\n",
    "    y = models_recall,\n",
    "    name='Recall',\n",
    "    marker=dict(\n",
    "        color='rgb(155, 244, 66)',\n",
    "    )\n",
    "    \n",
    ")\n",
    "# precision, recall, silhoutte\n",
    "data = [trace0, trace2,  trace1]\n",
    "layout = go.Layout(\n",
    "    title = 'Clustering Accuracy Results',\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=10,\n",
    "            color='rgb(107, 107, 107)',\n",
    "            \n",
    "        ),\n",
    "        tickangle = -45\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Clustering accuracy (%)',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "   \n",
    "    barmode='group',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename=graph_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhoutte score\n",
    "Silhouette coefficient combines ideas of both cohesion and separation, \n",
    "but for individual points, as well as clusters and \n",
    "clusterings; the Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample.\n",
    "The Silhoutte score is merely the average of each silhoutte coefficient, computed over each sample.\n",
    "It's a measure of the goodness of clustering, by assuming the fact that a cluster X is defined good if both every sample inside it is close to each other, and far from any other relatively-near cluster Y.\n",
    "This is not necessarily true for every shape of cluster.\n",
    "\n",
    "    The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115357034\n",
      "0.17881583\n",
      "0.17357981\n",
      "0.17970788\n",
      "0.22294052\n",
      "0.071362644\n",
      "0.28602874\n",
      "0.15391588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "s_scores = []\n",
    "for model in models:\n",
    "    # get clusters for each model\n",
    "    doc_vecs = [model.docvecs[j] for j in range(len(model.docvecs))]\n",
    "    titles = [doc['title'] for doc in unwrapped_docs]\n",
    "    urls = [doc['url'] for doc in unwrapped_docs]\n",
    "    # apply dbscan clustering to these vectors\n",
    "    urls_cluster_list = my_dbscan.apply_dbscan(doc_vecs = doc_vecs, titles = titles, \n",
    "                                               urls = urls, subset_length = len(titles),\n",
    "                                                 eps = 0.27, eps_increment = 0.1, n_iterations = 3, verbose = False)\n",
    "    \n",
    "    # get cluster labels, mantaining original docs ordering\n",
    "    labels = []\n",
    "    for doc in unwrapped_docs:\n",
    "        noise = True\n",
    "        for i, url_list in enumerate(urls_cluster_list):\n",
    "            if(doc['url'] in url_list):\n",
    "                labels.append(i) # keep cluster id\n",
    "                noise = False\n",
    "        if noise:\n",
    "            labels.append(-1)\n",
    "    # make sure they have the same size\n",
    "    assert len(labels) == len(doc_vecs)\n",
    "    ss = silhouette_score(doc_vecs, labels , metric='cosine')\n",
    "    s_scores.append(ss)\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions: \n",
    "A really low silhoutte score helps us identify models that tend to have very few cluster, hence not really recognizing differences between docs. This is fundamental, since test rules used so far prevent us from recognizing these kinds of models.\n",
    "Since silhoutte score is an average of silhoutte coefficients, smaller changes of values here may mean greater differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

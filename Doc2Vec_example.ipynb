{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a set of documents (a corpus) to train our model; we'll be using a default corpus included in gensim package\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "\n",
    "# Set file names for train and test data\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
    "lee_test_file = test_data_dir + os.sep + 'lee.cor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to read and preprocess (corpus) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                # 'yield' returns a generator, useful for large set of data (in terms of memory consumption)\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(lee_train_file))  # train data has tag associated to each document\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Doc2Vec object\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "\n",
    "# Essentially, the vocabulary is a dictionary (accessible via model.wv.vocab) of all of the unique words extracted\n",
    "# from the training corpus along with the count (e.g., model.wv.vocab['penalty'].count for counts for the word penalty).\n",
    "\n",
    "# this vocabulary is used to represent words and documents as vectors\n",
    "model.build_vocab(train_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.35 s, sys: 76 ms, total: 6.42 s\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring a vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16999331,  0.1012315 , -0.23506814, -0.01124856,  0.30688623,\n",
       "        0.16078861, -0.00644738, -0.16053137, -0.3081378 , -0.11048444,\n",
       "       -0.03026261, -0.01623827,  0.14595601,  0.0026754 ,  0.06123024,\n",
       "       -0.03907201, -0.07066187,  0.02581681,  0.13902222,  0.16819759,\n",
       "       -0.043812  ,  0.01738269, -0.02022651,  0.23334119,  0.13931751,\n",
       "       -0.05302273, -0.0102173 , -0.00827293, -0.08906103, -0.01244812,\n",
       "       -0.03293726,  0.02035635, -0.0130419 , -0.13051239,  0.366265  ,\n",
       "        0.13289651, -0.05009717, -0.03655452, -0.06671809,  0.02063492,\n",
       "        0.10780098,  0.05621843, -0.18863109, -0.1495434 ,  0.10851085,\n",
       "       -0.01378285,  0.10590136, -0.08507477,  0.03826743,  0.09270052],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One important thing to note is that you can now infer a vector for any piece of text \n",
    "# without having to re-train the model\n",
    "# This vector (generated from this document) can then be compared with other vectors via cosine similarity.\n",
    "model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "\n",
    "# Note that infer_vector() does not take a string, but rather a list of string tokens,\n",
    "# which should have already been tokenized the same way as the words property of original training document objects.\n",
    "\n",
    "# the underlying training/inference algorithms are an iterative approximation problem that makes use of internal randomization, \n",
    "# repeated inferences of the same text will return slightly different vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (10): «iraq and russia are close to signing billion economic cooperation plan iraq ambassador said saturday deal that could put moscow at odds with the united states as it considers military attack against baghdad the statement by ambassador abbas khalaf came amid indications that russia despite its strong support for the post sept antiterrorism coalition is maintaining or improving ties with iran and north korea which together with iraq are the countries president bush has labeled the axis of evil»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (26, 0.7779335975646973): «pakistan president pervez musharraf says he is ready to meet indian prime minister atal behari vajpayee as fears grow of war between the two countries tensions have escalated since suicide attack on the indian parliament two weeks ago india alleges the attack was backed by the pakistani intelligence service general musharraf says pakistan will never initiate conflict between the two countries he says he is prepared to hold talks with the indian prime minister at regional summit in nepal next week don mind meeting him but as ve said once before you can clap with one hand general musharraf said if there is willingness from the other side there will be willingness from my side»\n",
      "\n",
      "MEDIAN (60, 0.4006635546684265): «israel has rejected palestinian leader yasser arafat bid to make his annual visit to bethlehem for christmas eve during an security cabinet meeting early today the security cabinet made its decision based on the fact that arafat is not working to dismantle terror organizations and to foil terror attacks against israel and to arrest and punish terrorists including the murderers of tourism minister rhavam zeevi statement from prime minister ariel sharon office said earlier mr arafat declared he would walk to bethlehem for christmas eve mass if he has to if israeli authorities refused him access to the biblical town mr arafat statement comes as palestinians in gaza buried six teenagers killed in the worst internal palestinian violence in seven years the funerals in gaza were peaceful with palestinian police staying away and mourners agreeing no weapons were to be carried this has been difficult week for yasser arafat he put his reputation on the line by ordering the arrest of some key palestinian militants in the most important radical group hamas then declared an end to its campaign of suicide bombings and other attacks against israel another smaller but important radical group islamic jihad might follow hamas lead but the key to all this is israel reaction if it eases its blockade of towns in the west bank then yasser arafat will have something to show for his efforts»\n",
      "\n",
      "LEAST (168, 0.047958776354789734): «six swiss tour company staff have been found guilty of manslaughter over the deaths of australians and seven others in canyoning disaster two guides who survived the accident on july were acquitted adventure world president stephan friedli vice president peter balmer and director georg hoedle were each given five month suspended sentence and fine of swiss francs about general manager felix oehler received five months and fine of francs base manager bernhard gafner four months and francs and lead guide bernhard steuri three months and francs all six will pay one eighth of the court costs and one eighth of the plaintiffs costs about francs each guides simon wiget and stefan abegglen were acquitted peter dewar whose son bradley died in the disaster says more legal action is planned guess if anything the main thing we were waiting for was verdict of guilty or not guilty mr dewar said the guilty verdict at least leaves something open for civil action we already have legal representation in place mr dewar said he hopes civil action would be further form of punishment for the guilty bill peel of mackay in north queensland whose son billy died in the canyoning accident is disappointed with the verdict it swiss law and we have to abide by it was very angry very angry couldn believe it we were told this when the lawyer came to australia months ago but it was still hard to believe it was true oh well at least they are guilty and they have to live that the rest of their lives and that some punishment anyway mr peel said»\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\n",
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 2...\n",
      "Mean value of sigma: 33554432.000000\n",
      "Iteration 10: error is 5.545177\n",
      "Iteration 20: error is 5.545177\n",
      "Iteration 30: error is 5.545177\n",
      "Iteration 40: error is 5.545177\n",
      "Iteration 50: error is 5.545177\n",
      "Iteration 60: error is 5.545177\n",
      "Iteration 70: error is 5.545177\n",
      "Iteration 80: error is 5.545177\n",
      "Iteration 90: error is 5.545177\n",
      "Iteration 100: error is 5.545177\n",
      "Iteration 110: error is -0.000000\n",
      "Iteration 120: error is -0.000000\n",
      "Iteration 130: error is -0.000000\n",
      "Iteration 140: error is -0.000000\n",
      "Iteration 150: error is -0.000000\n",
      "Iteration 160: error is -0.000000\n",
      "Iteration 170: error is -0.000000\n",
      "Iteration 180: error is -0.000000\n",
      "Iteration 190: error is -0.000000\n",
      "Iteration 200: error is -0.000000\n",
      "Iteration 210: error is -0.000000\n",
      "Iteration 220: error is -0.000000\n",
      "Iteration 230: error is -0.000000\n",
      "Iteration 240: error is -0.000000\n",
      "Iteration 250: error is -0.000000\n",
      "Iteration 260: error is -0.000000\n",
      "Iteration 270: error is -0.000000\n",
      "Iteration 280: error is -0.000000\n",
      "Iteration 290: error is -0.000000\n",
      "Iteration 300: error is -0.000000\n",
      "Iteration 310: error is -0.000000\n",
      "Iteration 320: error is -0.000000\n",
      "Iteration 330: error is -0.000000\n",
      "Iteration 340: error is -0.000000\n",
      "Iteration 350: error is -0.000000\n",
      "Iteration 360: error is -0.000000\n",
      "Iteration 370: error is -0.000000\n",
      "Iteration 380: error is -0.000000\n",
      "Iteration 390: error is -0.000000\n",
      "Iteration 400: error is -0.000000\n",
      "Iteration 410: error is -0.000000\n",
      "Iteration 420: error is -0.000000\n",
      "Iteration 430: error is -0.000000\n",
      "Iteration 440: error is -0.000000\n",
      "Iteration 450: error is -0.000000\n",
      "Iteration 460: error is -0.000000\n",
      "Iteration 470: error is -0.000000\n",
      "Iteration 480: error is -0.000000\n",
      "Iteration 490: error is -0.000000\n",
      "Iteration 500: error is -0.000000\n",
      "Iteration 510: error is -0.000000\n",
      "Iteration 520: error is -0.000000\n",
      "Iteration 530: error is -0.000000\n",
      "Iteration 540: error is -0.000000\n",
      "Iteration 550: error is -0.000000\n",
      "Iteration 560: error is -0.000000\n",
      "Iteration 570: error is -0.000000\n",
      "Iteration 580: error is -0.000000\n",
      "Iteration 590: error is -0.000000\n",
      "Iteration 600: error is -0.000000\n",
      "Iteration 610: error is -0.000000\n",
      "Iteration 620: error is -0.000000\n",
      "Iteration 630: error is -0.000000\n",
      "Iteration 640: error is -0.000000\n",
      "Iteration 650: error is -0.000000\n",
      "Iteration 660: error is -0.000000\n",
      "Iteration 670: error is -0.000000\n",
      "Iteration 680: error is -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 690: error is -0.000000\n",
      "Iteration 700: error is -0.000000\n",
      "Iteration 710: error is -0.000000\n",
      "Iteration 720: error is -0.000000\n",
      "Iteration 730: error is -0.000000\n",
      "Iteration 740: error is -0.000000\n",
      "Iteration 750: error is -0.000000\n",
      "Iteration 760: error is -0.000000\n",
      "Iteration 770: error is -0.000000\n",
      "Iteration 780: error is -0.000000\n",
      "Iteration 790: error is -0.000000\n",
      "Iteration 800: error is -0.000000\n",
      "Iteration 810: error is -0.000000\n",
      "Iteration 820: error is -0.000000\n",
      "Iteration 830: error is -0.000000\n",
      "Iteration 840: error is -0.000000\n",
      "Iteration 850: error is -0.000000\n",
      "Iteration 860: error is -0.000000\n",
      "Iteration 870: error is -0.000000\n",
      "Iteration 880: error is -0.000000\n",
      "Iteration 890: error is -0.000000\n",
      "Iteration 900: error is -0.000000\n",
      "Iteration 910: error is -0.000000\n",
      "Iteration 920: error is -0.000000\n",
      "Iteration 930: error is -0.000000\n",
      "Iteration 940: error is -0.000000\n",
      "Iteration 950: error is -0.000000\n",
      "Iteration 960: error is -0.000000\n",
      "Iteration 970: error is -0.000000\n",
      "Iteration 980: error is -0.000000\n",
      "Iteration 990: error is -0.000000\n",
      "Iteration 1000: error is -0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "#  tsne.py\n",
    "#\n",
    "# Implementation of t-SNE in Python. The implementation was tested on Python\n",
    "# 2.7.10, and it requires a working installation of NumPy. The implementation\n",
    "# comes with an example on the MNIST dataset. In order to plot the\n",
    "# results of this example, a working installation of matplotlib is required.\n",
    "#\n",
    "# The example can be run by executing: `ipython tsne.py`\n",
    "#\n",
    "#\n",
    "#  Created by Laurens van der Maaten on 20-12-08.\n",
    "#  Copyright (c) 2008 Tilburg University. All rights reserved.\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "import random \n",
    "\n",
    "\n",
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "\n",
    "\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 1000 \n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "    # Pick a random document from the test corpus and infer a vector from the model\n",
    "    doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "    inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    similar_inferred_vector = model.infer_vector(train_corpus[sims[0][0]].words)\n",
    "    # Creating array np array with 2 rows: one row is the inferred_vector, the second one is the most\n",
    "    # similar document vector\n",
    "    \n",
    "    X = np.array([inferred_vector, similar_inferred_vector])\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    #pylab.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "    pylab.scatter(Y[:, 0], Y[:, 1])\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

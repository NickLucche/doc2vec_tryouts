{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how testing is going to work\n",
    "Take 3 documents: 2 similar, and a 1 quite different; check if model recognizes this difference,\n",
    "which results, in the live version, to not group the three articles in the same region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and infer vectors from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import  gensim\n",
    "\n",
    "MODEL_NAME = 'TestModels/d2v_TA_abstract&title0.model'\n",
    "MODEL_TWO = 'Models/d2v_TA_abstract&title0.model'\n",
    "#model = Doc2Vec.load(MODEL_NAME)\n",
    "model = Doc2Vec.load(MODEL_TWO)\n",
    "inferred_vectors = []\n",
    "# print out dimension of the vocabulary \n",
    "print(len(model.wv.vocab))\n",
    "#print(model.most_similar(positive=['re', 'donna'], negative=['uomo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wikipedia articles test-set\n",
    "other approach: DBSCAN the vectors inferred from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 27 articles\n",
      "Italia is similar to Berlino with a score of: [[0.52789956]]\n",
      "\n",
      "Italia is similar to Parigi with a score of: [[0.55656326]]\n",
      "\n",
      "Italia is similar to Bologna with a score of: [[0.5959468]]\n",
      "\n",
      "Italia is similar to Roma with a score of: [[0.5449377]]\n",
      "\n",
      "Italia is similar to Milano with a score of: [[0.5863396]]\n",
      "\n",
      "Berlino is similar to Italia with a score of: [[0.52789956]]\n",
      "\n",
      "Berlino is similar to Parigi with a score of: [[0.6624329]]\n",
      "\n",
      "Berlino is similar to Londra with a score of: [[0.54691124]]\n",
      "\n",
      "Berlino is similar to Bologna with a score of: [[0.5238744]]\n",
      "\n",
      "Berlino is similar to Roma with a score of: [[0.5870053]]\n",
      "\n",
      "Berlino is similar to USA with a score of: [[0.51547414]]\n",
      "\n",
      "Berlino is similar to Milano with a score of: [[0.57719976]]\n",
      "\n",
      "Berlino is similar to Quirinale with a score of: [[0.5933477]]\n",
      "\n",
      "Colosseo is similar to New York with a score of: [[0.59265566]]\n",
      "\n",
      "Colosseo is similar to Parigi with a score of: [[0.5562386]]\n",
      "\n",
      "Colosseo is similar to Londra with a score of: [[0.5239558]]\n",
      "\n",
      "Colosseo is similar to Bologna with a score of: [[0.52297217]]\n",
      "\n",
      "Colosseo is similar to Roma with a score of: [[0.57675266]]\n",
      "\n",
      "Colosseo is similar to Pizza with a score of: [[0.5108006]]\n",
      "\n",
      "New York is similar to Colosseo with a score of: [[0.59265566]]\n",
      "\n",
      "New York is similar to Parigi with a score of: [[0.55876756]]\n",
      "\n",
      "New York is similar to Bologna with a score of: [[0.5408217]]\n",
      "\n",
      "New York is similar to USA with a score of: [[0.54268205]]\n",
      "\n",
      "New York is similar to Quirinale with a score of: [[0.5164187]]\n",
      "\n",
      "Ciliegia is similar to Melone with a score of: [[0.5396422]]\n",
      "\n",
      "Parigi is similar to Italia with a score of: [[0.55656326]]\n",
      "\n",
      "Parigi is similar to Berlino with a score of: [[0.6624329]]\n",
      "\n",
      "Parigi is similar to Colosseo with a score of: [[0.5562386]]\n",
      "\n",
      "Parigi is similar to New York with a score of: [[0.55876756]]\n",
      "\n",
      "Parigi is similar to Bologna with a score of: [[0.5082079]]\n",
      "\n",
      "Parigi is similar to Roma with a score of: [[0.5566193]]\n",
      "\n",
      "Parigi is similar to Milano with a score of: [[0.5602627]]\n",
      "\n",
      "Parigi is similar to Quirinale with a score of: [[0.5277616]]\n",
      "\n",
      "Londra is similar to Berlino with a score of: [[0.54691124]]\n",
      "\n",
      "Londra is similar to Colosseo with a score of: [[0.5239558]]\n",
      "\n",
      "Londra is similar to Bologna with a score of: [[0.5221552]]\n",
      "\n",
      "Londra is similar to Roma with a score of: [[0.5822119]]\n",
      "\n",
      "Londra is similar to Quirinale with a score of: [[0.52064085]]\n",
      "\n",
      "Bologna is similar to Italia with a score of: [[0.5959468]]\n",
      "\n",
      "Bologna is similar to Berlino with a score of: [[0.5238744]]\n",
      "\n",
      "Bologna is similar to Colosseo with a score of: [[0.52297217]]\n",
      "\n",
      "Bologna is similar to New York with a score of: [[0.5408217]]\n",
      "\n",
      "Bologna is similar to Parigi with a score of: [[0.5082079]]\n",
      "\n",
      "Bologna is similar to Londra with a score of: [[0.5221552]]\n",
      "\n",
      "Bologna is similar to Roma with a score of: [[0.52291554]]\n",
      "\n",
      "Bologna is similar to Milano with a score of: [[0.61404276]]\n",
      "\n",
      "Bologna is similar to Quirinale with a score of: [[0.51897883]]\n",
      "\n",
      "Roma is similar to Italia with a score of: [[0.5449377]]\n",
      "\n",
      "Roma is similar to Berlino with a score of: [[0.5870053]]\n",
      "\n",
      "Roma is similar to Colosseo with a score of: [[0.57675266]]\n",
      "\n",
      "Roma is similar to Parigi with a score of: [[0.5566193]]\n",
      "\n",
      "Roma is similar to Londra with a score of: [[0.5822119]]\n",
      "\n",
      "Roma is similar to Bologna with a score of: [[0.52291554]]\n",
      "\n",
      "Roma is similar to Milano with a score of: [[0.6100769]]\n",
      "\n",
      "Roma is similar to Quirinale with a score of: [[0.5721116]]\n",
      "\n",
      "Melone is similar to Ciliegia with a score of: [[0.5396422]]\n",
      "\n",
      "Melone is similar to Banana with a score of: [[0.5106467]]\n",
      "\n",
      "Banana is similar to Melone with a score of: [[0.5106467]]\n",
      "\n",
      "USA is similar to Berlino with a score of: [[0.51547414]]\n",
      "\n",
      "USA is similar to New York with a score of: [[0.54268205]]\n",
      "\n",
      "Pizza is similar to Colosseo with a score of: [[0.5108006]]\n",
      "\n",
      "Milano is similar to Italia with a score of: [[0.5863396]]\n",
      "\n",
      "Milano is similar to Berlino with a score of: [[0.57719976]]\n",
      "\n",
      "Milano is similar to Parigi with a score of: [[0.5602627]]\n",
      "\n",
      "Milano is similar to Bologna with a score of: [[0.61404276]]\n",
      "\n",
      "Milano is similar to Roma with a score of: [[0.6100769]]\n",
      "\n",
      "Quirinale is similar to Berlino with a score of: [[0.5933477]]\n",
      "\n",
      "Quirinale is similar to New York with a score of: [[0.5164187]]\n",
      "\n",
      "Quirinale is similar to Parigi with a score of: [[0.5277616]]\n",
      "\n",
      "Quirinale is similar to Londra with a score of: [[0.52064085]]\n",
      "\n",
      "Quirinale is similar to Bologna with a score of: [[0.51897883]]\n",
      "\n",
      "Quirinale is similar to Roma with a score of: [[0.5721116]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('wikipedia_dump.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "print(\"We have {} articles\".format(len(json_data)))\n",
    "titles = []\n",
    "inferred_vectors = []\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "for dictionary in json_data:\n",
    "    inferred_vectors.append(model.infer_vector(gensim.utils.simple_preprocess(dictionary['abstract'])))\n",
    "    titles.append(dictionary['title'])\n",
    "assert len(titles)==len(inferred_vectors)\n",
    "\n",
    "# for now, let's just print out documents similiraties among them\n",
    "for i, docvec in enumerate(inferred_vectors):\n",
    "    for j, docv in enumerate(inferred_vectors):\n",
    "        # let's just write out the most similar vectors\n",
    "        sim = cosine_similarity([docvec], [docv])\n",
    "        if sim>=similarity_threshold and i != j:\n",
    "            #print(\"{0} is similar to {1} with a score of: {2}\\n\".format(titles[i], titles[j], sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my function for performing dbscan and printing out cluster results\n",
    "def perform_dbscan(eps = 0.4, min_samples = 4, metric = 'euclidean', algorithm = 'auto', data = None, verbose = True\n",
    "                  , titles = None, print_noise = True):\n",
    "    \"\"\"perform DBSCAN over given data, using given parametrs. Returns dbscan object and clusters dictionary.\"\"\"\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm).fit(data)\n",
    "\n",
    "    # labels will print out the number of the cluster each example belongs to;\n",
    "    # -1 if the vector is considered noise (not belonging to any cluster)\n",
    "    #print(\"Labels: \", db.labels_)\n",
    "\n",
    "    # create data structure containing clusters\n",
    "    clusters_to_ret = {label:[] for label in db.labels_ if label!=-1}\n",
    "    \n",
    "    for i, label in enumerate(db.labels_):\n",
    "        if label != -1: #ignore noise points\n",
    "            clusters_to_ret[label].append(urls[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # only do this if you need to print out the result (messy for large number of docs)\n",
    "    if verbose:\n",
    "        print(\"##Clusters##\")\n",
    "        clusters = {label: [] for label in db.labels_ if label!=-1}\n",
    "        noise = []\n",
    "        for i, label in enumerate(db.labels_):\n",
    "            if label != -1: \n",
    "                clusters[label].append(titles[i])\n",
    "            else: # save noise points\n",
    "                noise.append(titles[i])\n",
    "                \n",
    "        for label, list_ in clusters.items():\n",
    "            print(\"Cluster {0}: {1}\".format(label, list_))\n",
    "        if print_noise:\n",
    "            print(\"Noise: \", noise)\n",
    "\n",
    "        print(\"DBSCAN finished.\\n\")\n",
    "    return db, clusters_to_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN incremental version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Clusters##\n",
      "Cluster: ['Berlino', 'Parigi']\n",
      "Cluster: ['Bologna', 'Roma', 'Milano']\n",
      "Noise:  ['Microsoft', 'Lampone', 'Casa Bianca', 'Italia', 'Amazon', 'Colosseo', 'New York', 'Instagram', 'Ciliegia', 'Mela', 'Pasta', 'Londra', 'Melone', 'Banana', 'Facebook', 'USA', 'Pizza', 'Quirinale', 'Pera', 'Google', 'Apple', 'Hot dog']\n",
      "DBSCAN finished.\n",
      "\n",
      "##Clusters##\n",
      "Cluster: ['Microsoft', 'Apple']\n",
      "Cluster: ['Lampone', 'Ciliegia', 'Mela', 'Melone', 'Banana', 'Pera']\n",
      "Cluster: ['Casa Bianca', 'Italia', 'Colosseo', 'New York', 'Londra', 'USA', 'Pizza', 'Quirinale']\n",
      "Cluster: ['Instagram', 'Facebook', 'Google']\n",
      "Noise:  ['Amazon', 'Pasta', 'Hot dog']\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DBSCAN the mini-set of docs from wikipedia\n",
    "eps = 0.4\n",
    "eps_increment = .15\n",
    "db = perform_dbscan(eps = eps, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = inferred_vectors, verbose = True, titles = titles)\n",
    "noise_data = [inferred_vectors[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "noise_titles = [titles[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "db = perform_dbscan(eps = eps + eps_increment, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = noise_data, verbose = True, titles = noise_titles)\n",
    "print('Done')\n",
    "# let's try and find other clusters in the noise data, with higher eps\n",
    "noise_data = [inferred_vectors[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "noise_titles = [titles[i] for i, label in enumerate(db.labels_) if label==-1]\n",
    "db = perform_dbscan(eps = eps + eps_increment, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = noise_data, verbose = True, titles = noise_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Clusters##\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d62a8e9df989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mperform_dbscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-998a2e141cd6>\u001b[0m in \u001b[0;36mperform_dbscan\u001b[0;34m(eps, min_samples, metric, algorithm, data, verbose, titles)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnoise_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlist_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# let's try out different options\n",
    "\n",
    "#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.5, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.45, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.55, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia 3-documents-test\n",
    "Test our model with 2 similar documents, and one chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 81 docs tuples\n"
     ]
    }
   ],
   "source": [
    "# 2 documents are similar if they get a score higher than this threshold\n",
    "# - based on cosine similarity -\n",
    "similarity_threshold = 0.4\n",
    "\n",
    "# load file\n",
    "import json\n",
    "with open('wikipedia_3docs_dump.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "print(\"We have {} docs tuples\".format(len(json_data)))\n",
    "titles = []\n",
    "inferred_vectors = [] # list of lists\n",
    "\n",
    "# infer each document vector\n",
    "for dic_list in json_data:\n",
    "    vectors = []\n",
    "    for dictionary in dic_list:\n",
    "        vec = model.infer_vector(gensim.utils.simple_preprocess(dictionary['abstract']))\n",
    "        vectors.append(vec)\n",
    "        titles.append(dictionary['title'])\n",
    "    inferred_vectors.append(vectors)\n",
    "    \n",
    "#print(inferred_vectors[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Infante, 'Figlio')---Argentina Open 2016 - Doppio\n",
      "Guessed right!\n",
      "('Uomo, 'Donna')---Emicrania emiplegica familiare\n",
      "Not similar  [[0.22392115]]\n",
      "('Samsung, 'LG')---Piazza Carlo III (Napoli)\n",
      "Guessed right!\n",
      "('Milano, 'Bologna')---Maria Elena Vandone\n",
      "Similar 0-2 [[0.4779811]]\n",
      "('Re, 'Principe')---Candia (unità periferica)\n",
      "Guessed right!\n",
      "('Roma, 'Berlino')---Qawmī Tarāna\n",
      "Similar 0-2 [[0.47933146]]\n",
      "('Armi, 'Pistola')---Otov\n",
      "Not similar  [[0.37634563]]\n",
      "('Brodo, 'Zuppa')---Babette von Bülow\n",
      "Guessed right!\n",
      "('Incendio, 'Bruciare')---Criptomorfismo\n",
      "Not similar  [[0.14342284]]\n",
      "('Questione, 'Domanda')---Calzino\n",
      "Not similar  [[0.29680198]]\n",
      "('iPad, 'iPhone')---Leggi sulla sodomia negli Stati Uniti d'America\n",
      "Guessed right!\n",
      "('Chino, 'Curvo')---Battaglia di Thouars\n",
      "Not similar  [[0.13092655]]\n",
      "('Regina, 'Principessa')---Aeroporto di Rževka\n",
      "Not similar  [[0.33889288]]\n",
      "('Ghepardo, 'Tigre')---Christian Georg Schmorl\n",
      "Similar 1-2 [[0.42288837]]\n",
      "('Cadere, 'Cascare')---Edward Fletcher\n",
      "Similar 0-2 [[0.4400044]]\n",
      "('Instagram, 'Facebook')---Rec.Sport.Soccer Statistics Foundation\n",
      "Guessed right!\n",
      "('RHCP, 'Guns n roses')---Annio Eucario Epifanio\n",
      "Not similar  [[0.31595486]]\n",
      "('Italiani, 'Italia')---All Stars Football Club\n",
      "Similar 0-2 [[0.440008]]\n",
      "('Cucciolo, 'Bambino')---Here Comes Science\n",
      "Not similar  [[0.3311553]]\n",
      "('Intelligenza Artificiale, 'Machine Learning')---UNOMIL\n",
      "Guessed right!\n",
      "('Cane, 'Gatto')---Arizona State Sun Devils football\n",
      "Not similar  [[0.3896535]]\n",
      "('Juventus, 'Real Madrid')---Oost-Cappel\n",
      "Similar 0-2 [[0.425076]]\n",
      "('Corto, 'Succinto')---Jesse (disambigua)\n",
      "Not similar  [[0.2319316]]\n",
      "('Parigi, 'Torre Eiffel')---Marcello Argilli\n",
      "Guessed right!\n",
      "('Leopardo, 'Pantera nera')---Una tragedia al cinematografo\n",
      "Not similar  [[0.3468697]]\n",
      "('Molto, 'Assai')---Charles Jensen\n",
      "Not similar  [[0.28473797]]\n",
      "('Astronomia, 'Pianeta')---Gobichettipalayam\n",
      "Similar 0-2 [[0.41449258]]\n",
      "('Ginnasio, 'Palestra')---Bakong\n",
      "Not similar  [[0.37936342]]\n",
      "('Vita Nuova, 'Divina Commedia')---Cantabri\n",
      "Similar 1-2 [[0.40637788]]\n",
      "('Benestante, 'Ricco')---Calcinate\n",
      "Not similar  [[0.25677222]]\n",
      "('NASA, 'Marte')---Open 13 2014 - Doppio\n",
      "Not similar  [[0.37618]]\n",
      "('Lampone, 'Melone')---Plutone (divinità)\n",
      "Not similar  [[0.29671487]]\n",
      "('Google, 'Amazon')---Callaway Cars\n",
      "Not similar  [[0.3665191]]\n",
      "('Cane, 'Lupo')---Beautiful World Live\n",
      "Guessed right!\n",
      "('Principe, 'Principessa')---To My Wonderful One\n",
      "Not similar  [[0.3417496]]\n",
      "('Android, 'Smartphone')---Josep Maria Junoy i Muns\n",
      "Guessed right!\n",
      "('Chiocciola, 'Lumaca')---Horní Pěna\n",
      "Not similar  [[0.31851858]]\n",
      "('Gallus gallus domesticus, 'Tacchino')---Vytautas Kernagis\n",
      "Not similar  [[0.22972745]]\n",
      "('Madre, 'Figlia')---Spazio vettoriale quoziente\n",
      "Guessed right!\n",
      "('Guelfi, 'Ghibellini')---Maglio (Goito)\n",
      "Similar 0-2 [[0.46792376]]\n",
      "('Leopardo, 'Puma')---Sauvo\n",
      "Not similar  [[0.25045717]]\n",
      "('Banana, 'Ciliegia')---Möhnesee\n",
      "Guessed right!\n",
      "('Bambino, 'Bambina')---Narcy\n",
      "Guessed right!\n",
      "('Figlio, 'Bambino')---Musée des Beaux-Arts (Tours)\n",
      "Not similar  [[0.3688138]]\n",
      "('Apple, 'Microsoft')---Collerico\n",
      "Guessed right!\n",
      "('Parigi, 'Londra')---Cilindro (serratura)\n",
      "Guessed right!\n",
      "('Maiale, 'Cinghiale')---The Blue Hour (album)\n",
      "Not similar  [[0.34493607]]\n",
      "('iPhone, 'Smartphone')---Unione Sportiva Bagnolese 1937-1938\n",
      "Guessed right!\n",
      "('Fuoco, 'Fiamme')---Corrosion of Conformity\n",
      "Not similar  [[0.3940943]]\n",
      "('Cina, 'Pechino')---Romanzi di Higurashi no naku koro ni\n",
      "Guessed right!\n",
      "('Zio, 'Zia')---Acokanthera\n",
      "Not similar  [[0.25984907]]\n",
      "('Tigre, 'Leopardo')---Diocesi di Foro Flaminio\n",
      "Not similar  [[0.3731821]]\n",
      "('Francesi, 'Francia')---Piergiorgio Farina\n",
      "Guessed right!\n",
      "('Mucca, 'Toro')---Villa Bernocchi (Legnano)\n",
      "Guessed right!\n",
      "('Marte (astronomia), 'Venere (astronomia)')---The Story of a Cocoanut\n",
      "Guessed right!\n",
      "('Bestia, 'Animale')---The Hollywood Vampires\n",
      "Similar 0-2 [[0.41898456]]\n",
      "('Matematica, 'Fisica')---Giovanni Bertone\n",
      "Guessed right!\n",
      "('Robot, 'Intelligenza Artificiale')---Corri ragazzo\n",
      "Not similar  [[0.15123248]]\n",
      "('Amazon, 'e-commerce')---Manerba del Garda\n",
      "Not similar  [[0.38350195]]\n",
      "('Figlio, 'Padre')---Nazionale Under-18 di pallavolo femminile del Venezuela\n",
      "Guessed right!\n",
      "('Fratello, 'Sorella')---David Nainkin\n",
      "Guessed right!\n",
      "('Acqua, 'Ghiaccio')---Campionati del mondo di atletica leggera 1991 - Eptathlon\n",
      "Guessed right!\n",
      "('Mela, 'Pera')---Cloaca Massima\n",
      "Guessed right!\n",
      "('Sogno, 'Sognare')---Tokyo Road: Best of Bon Jovi\n",
      "Not similar  [[0.22791097]]\n",
      "('Intel, 'AMD')---Cassistrellus\n",
      "Guessed right!\n",
      "('Matematica, 'Ingegneria')---Susan Hinton\n",
      "Guessed right!\n",
      "('Padre, 'Nonno')---Fontanelle (album)\n",
      "Not similar  [[0.34024256]]\n",
      "('Vento, 'Uragano')---Episodi di 30 Rock (settima stagione)\n",
      "Not similar  [[0.38127482]]\n",
      "('Francia, 'Italia')---Il gabbiano\n",
      "Guessed right!\n",
      "('Mark Zuckerberg, 'Facebook')---Torre Kuchlbauer\n",
      "Guessed right!\n",
      "('Armata, 'Esercito')---Royal Dauphins Mouscronnois\n",
      "Not similar  [[0.38232416]]\n",
      "('Madre, 'Nonna')---Uran (città)\n",
      "Similar 0-2 [[0.4284354]]\n",
      "('Piccione, 'Rondine')---Hoff\n",
      "Guessed right!\n",
      "('Cavallo, 'Pony')---Contea di Fluvanna\n",
      "Not similar  [[0.28244698]]\n",
      "('Valvassore, 'Valvassino')---Le Thoureil\n",
      "Guessed right!\n",
      "('Nonno, 'Nipote')---Page One. Un anno dentro il New York Times\n",
      "Not similar  [[0.39023983]]\n",
      "('Cometa, 'Stella')---Sportitalia Mercato\n",
      "Guessed right!\n",
      "('Apple, 'Samsung')---Jim Smith\n",
      "Guessed right!\n",
      "('Cappello, 'Berretto')---Max Schwabe\n",
      "Guessed right!\n",
      "('Re, 'Regina')---Visay Phapouvanin\n",
      "Not similar  [[0.3587471]]\n",
      "('Imperatore, 'Imperatrice')---Guillaume le Rouge\n",
      "Guessed right!\n",
      "Correct guesses: 35 over 81 examples\n"
     ]
    }
   ],
   "source": [
    "# a model gives a correct answer if it correctly classifies the 2 'linked-document' \n",
    "# as similar, and the third one as dissimilar to both\n",
    "correct = 0\n",
    "j = 0\n",
    "for i, linked_docs in enumerate(inferred_vectors):\n",
    "    print(\"('{0}, '{1}')---{2}\".format(titles[j], titles[j+1], titles[j+2]))\n",
    "    j = j+3\n",
    "    cosine_s = cosine_similarity([linked_docs[0]], [linked_docs[1]])\n",
    "    if cosine_s<similarity_threshold:\n",
    "        print(\"Not similar \", cosine_s)\n",
    "        continue\n",
    "    cosine_s = cosine_similarity([linked_docs[0]], [linked_docs[2]])\n",
    "    if cosine_s > similarity_threshold:\n",
    "        print(\"Similar 0-2\", cosine_s)\n",
    "        continue\n",
    "    cosine_s = cosine_similarity([linked_docs[1]], [linked_docs[2]])\n",
    "    if cosine_s > similarity_threshold:\n",
    "        print(\"Similar 1-2\", cosine_s)\n",
    "        continue\n",
    "    correct = correct + 1\n",
    "    print(\"Guessed right!\")\n",
    "    \n",
    "print(\"Correct guesses: {0} over {1} examples\".format(correct, len(inferred_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out test corpus Clustering and Visualization\n",
    "kind of a live-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  200\n"
     ]
    }
   ],
   "source": [
    "## load test-corpus\n",
    "import json\n",
    "import gensim\n",
    "\n",
    "with open('TOWL_test_corpus.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "titles = [dictionary['title'] for dictionary in json_data]\n",
    "test_corpus = [gensim.utils.simple_preprocess(d['title']+d['abstract']) for d in json_data]\n",
    "#test_corpus = [gensim.utils.simple_preprocess(d['flattened_entities']) for d in json_data]\n",
    "print(\"Number of documents: \", len(test_corpus))\n",
    "#print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  0 -1 -1 -1 -1 -1 -1  1  2 -1  3 -1  4  5 -1 -1 -1  6 -1  7 -1 -1\n",
      "  4  4 -1 -1  0 -1 -1 -1  5 -1 -1 -1 -1 -1 -1  5  7 -1 -1  2  8 -1 -1 -1\n",
      " -1  1 -1 -1  5  5 -1  5 -1 -1 -1 -1  9 -1 -1 -1 -1 -1 10 11 -1 -1 -1 -1\n",
      "  5 -1 -1  7 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 10 -1 -1 -1 -1  5 -1 -1 -1 -1\n",
      " -1 -1 -1 12 -1 13  3 -1  4 -1 14 -1 -1  4 -1 -1  5 -1 -1 -1 -1 -1  7 -1\n",
      " 12 -1 -1 -1 -1  4 -1 -1 -1 -1 -1  5  8 12  5 -1 13  5 14 -1 11 -1 -1 -1\n",
      "  8 -1 -1 -1 -1 -1 -1 -1 -1  5 13 -1 -1 -1 -1 -1 -1 -1 -1  3 -1 -1 13  4\n",
      " 15  9 -1 15 -1  4 -1  5 -1 -1 -1 -1 -1 -1 -1 -1  2 -1 -1 -1  5  4  3 -1\n",
      " -1  5  6 -1 -1 -1 13 -1]\n"
     ]
    }
   ],
   "source": [
    "# for each document in the test corpus, infer a vector\n",
    "inferred_vectors = [model.infer_vector(test_doc) for test_doc in test_corpus]\n",
    "# and perform db scan\n",
    "db = perform_dbscan(eps = 0.48, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = inferred_vectors, verbose = False, titles = titles)\n",
    "print(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0 -1  0 -1  0  0  0 -1\n",
      "  0  0  0  1 -1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0\n",
      "  0  0  0  0  0  0 -1  0  0 -1  0  0  0  0  0  0  0 -1  0 -1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0\n",
      "  0  0 -1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0\n",
      "  1  0  0 -1  0  0 -1  0  0  0 -1  0  0  0  0 -1  0  0  0  0  0  0  0 -1\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# we have a lot of noise points; let's try to dbscan those points again, with a higher eps\n",
    "#print(cosine_similarity([inferred_vectors[0]], [inferred_vectors[3]]))\n",
    "# create a list of noise inferred vectors\n",
    "noise = [inferred_vectors[i] for i, index in enumerate(db.labels_) if index==-1]\n",
    "db = perform_dbscan(eps = 0.52, min_samples = 3, metric = 'cosine', algorithm = 'brute',\n",
    "                    data = inferred_vectors, verbose = False)\n",
    "#print(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "db = perform_dbscan(eps = 0.25, min_samples = 2, metric = 'cosine', algorithm = 'brute',\n",
    "                    data = pairwise_distances(inferred_vectors, metric='manhattan'), verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualizing using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# loading dataset into Pandas DataFrame\n",
    "df = pd.DataFrame.from_records(inferred_vectors)\n",
    "# PCA is effected by scale so you need to scale the features in your data before applying PCA. \n",
    "vec_size = 100\n",
    "features = [i for i in range(vec_size)]\n",
    "\n",
    "x = df.loc[:, features].values # get features values\n",
    "# standardize data\n",
    "x = StandardScaler().fit_transform(x) # scale data (especially in case different measures are used)\n",
    "# build PCA model in 2D\n",
    "pca = PCA(n_components=2) # The new components are just the two main dimensions of variation.\n",
    "\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf.head()\n",
    "# these components drawn don't hold a lot of information 'per-se', they're just the result \n",
    "# of dimension-reduction\n",
    "\n",
    "finalDf = principalDf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3/42.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "from scipy.spatial import distance\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3', api_key='FdMB4O6qCfciGDOnLvdQ')\n",
    "\n",
    "COMPONENT_ONE = \"principal component 1\"\n",
    "COMPONENT_TWO = \"principal component 2\"\n",
    "\n",
    "traces = []\n",
    "clusters_indices = db.labels_\n",
    "\n",
    "assert len(finalDf)==len(clusters_indices)\n",
    "# each trace will represent a point (squeezed vector from higher dimensions),\n",
    "# and each point will have the title of the news assigned\n",
    "for i in range(len(finalDf)):\n",
    "    x , y = finalDf.iat[i, 0], finalDf.iat[i, 1]\n",
    "    color = 'rgba(0, 0, 180, 0.8)'\n",
    "    \"\"\"\n",
    "    # print colors according to cluster\n",
    "    if clusters_indices[i]==-1:\n",
    "        color = 'black'\n",
    "    else:\n",
    "        red = 10 * clusters_indices[i]\n",
    "        color = 'rgba({}, 0, 120, .9)'.format(red)\n",
    "    \"\"\"\n",
    "    if clusters_indices[i]==0:\n",
    "        color = 'red'\n",
    "    elif clusters_indices[i]==1:\n",
    "        color = 'pink'\n",
    "    elif clusters_indices[i]==2:\n",
    "        color = 'yellow'\n",
    "    elif clusters_indices[i]==3:\n",
    "        color = 'blue'\n",
    "    elif clusters_indices[i]==4:\n",
    "        color = 'violet'\n",
    "    elif clusters_indices[i]==5:\n",
    "        color = 'rgba(100, 100, 100, 1)'\n",
    "    elif clusters_indices[i]==-1:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    \n",
    "    trace0 = go.Scatter(\n",
    "        x = [x], \n",
    "        y = [y],\n",
    "        mode = 'markers',\n",
    "            #name = 'blue markers',\n",
    "        marker = dict(\n",
    "            size = 7,\n",
    "            color = color,\n",
    "        ),\n",
    "        text = str(titles[i])\n",
    "    )\n",
    "    traces.append(trace0)\n",
    "\n",
    "data = traces \n",
    "layout = dict(title = 'PCA Representantion of Test Data with DBSCAN',\n",
    "            hovermode= 'closest',\n",
    "            xaxis= dict(\n",
    "                title= 'first component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title= 'second component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            showlegend = False\n",
    "        )\n",
    "# Plot and embed in ipython notebook!\n",
    "    \n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename='TOWL_model_testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of small test sub-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Clusters##\n",
      "Cluster: ['3 Italia, la rete dati non funziona. Ecco cosa sta succedendo - Wired', '3 Italia, la rete dati non funziona. Ecco cosa sta succedendo - Wired']\n",
      "Cluster: ['Realtà virtuale: il mercato a un punto di svolta', 'Realtà virtuale: il mercato a un punto di svolta']\n",
      "Noise:  ['I capelli hanno fiuto, molecole odorose li aiutano a crescere - Repubblica.it', 'Ecco perché WhatsApp non funzionava (e se fosse colpa della Juve?) - Corriere.it', 'Intrattenimento', 'Un bug sta paralizzando le poste francesi - Wired', 'Tech: tutti i contenuti per gallery - Pagina 5 - Wired', 'Marchesan, un\\'italiana tra gli scienziati emergenti nel mondo: \"La sfida più grande? Le differenze di genere\" - Repubblica.it', 'Asimo va in pensione, quale sarà il futuro dei robot umanoidi? - Wired', 'La navigazione in incognito è meno sicura di quanto si creda - Repubblica.it', 'Your Phone: dallo smartphone a Windows 10', \"Fb, 'war room' in vista voto Usa e Ue - Internet e Social - ANSA.it\", 'Microsoft annuncia il nuovo controller Xbox a prova di unto - Corriere.it', 'Synfig | Punto Informatico', 'NeoOffice | Punto Informatico', 'Tingersi i capelli con il grafene', 'Skype down, problemi di connessione in tutta Europa - Corriere.it', 'Speciale Ignite 2018', 'Ufo, Alieni, Extraterrestri, Ovni, Mistero bUFO, Giochi Pechino, Dario Fo, Mistero Buffo, Il bivio, Enrico Ruggeri, Mediaset, Corriere.it, Giovanni Angeli', 'Perché i fondatori di Instagram hanno lasciato la società - La Stampa', 'Acrobat DC, così Adobe ridefinisce il PDF', 'Come funziona Hunova, il robot italiano per la riabilitazione - Wired', 'WhatsApp può svelare quando dormi e con chi chatti - Corriere.it']\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's take a few documents, randomly chosen from the inferred vectors\n",
    "import random\n",
    "subsample_size = 25\n",
    "subsamples = []\n",
    "titles2 = []\n",
    "for i in range(subsample_size):\n",
    "    index = random.randint(0, len(inferred_vectors)-1)\n",
    "    subsamples.append(inferred_vectors[index])\n",
    "    titles2.append(titles[index])\n",
    "    \n",
    "db = perform_dbscan(eps = 0.48, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = subsamples, verbose = True, titles = titles2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model, data, and test DBSCAN on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import json\n",
    "import random\n",
    "#import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "import  gensim\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 96\n",
      "New length after removing docs:  91\n",
      "Number of docs: 599\n",
      "New length after removing docs:  362\n"
     ]
    }
   ],
   "source": [
    "filenames = ['blockchain.json', 'industria_4.0.json']\n",
    "\n",
    "# load multiple files, assuming same data format\n",
    "docs = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as outfile:\n",
    "        json_data = json.load(outfile)\n",
    "\n",
    "    ## let's now retrieve the meaningful part of the json document\n",
    "    # response{}--->docs[] \n",
    "\n",
    "    docs = docs + json_data['response']['docs']\n",
    "    print(\"Number of docs:\",len(docs))\n",
    "    ## many documents have a failed abstract, let's remove them\n",
    "    to_check = ' Questo sito web utilizza cookie tecnici e, previo Suo consenso, cookie di profilazione,'\n",
    "    docs = [doc for i, doc in enumerate(docs) if not(to_check.strip() in doc['abstract'][0].strip())]\n",
    "\n",
    "    # remove duplicates (of a particular doc)\n",
    "    # TODO: remove all duplicates\n",
    "    docs = [doc for doc in docs\n",
    "                if not(\"Industry 4.0 (o industria 4.0): cos'Ã¨, notizie, normative, casi studio - I4T\" in doc['title'])]\n",
    "    print(\"New length after removing docs: \", len(docs))\n",
    "    \n",
    "## Adjust data format: title, abstract and url came in as list, but they're more useful as strings\n",
    "for i, dictionary in enumerate(docs):\n",
    "    for field in ['title', 'abstract', 'url']:\n",
    "        if isinstance(dictionary[field], list):\n",
    "            # re-format data to hold string instead of single-list item\n",
    "            docs[i][field] = dictionary[field][0]   \n",
    "            \n",
    "MODEL_NAME = 'TestModels/w2v_entities+abstract_model.model'\n",
    "model = Word2Vec.load(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my function for performing dbscan and printing out cluster results\n",
    "def perform_dbscan(eps = 0.4, min_samples = 4, metric = 'euclidean', algorithm = 'auto', data = None, verbose = True\n",
    "                  , titles = None, urls = None, print_noise = True):\n",
    "    \"\"\"perform DBSCAN over given data, using given parametrs. Returns dbscan object and clusters dictionary.\"\"\"\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm).fit(data)\n",
    "\n",
    "    # labels will print out the number of the cluster each example belongs to;\n",
    "    # -1 if the vector is considered noise (not belonging to any cluster)\n",
    "    #print(\"Labels: \", db.labels_)\n",
    "\n",
    "    # create data structure containing clusters\n",
    "    clusters_to_ret = {label:[] for label in db.labels_ if label!=-1}\n",
    "    \n",
    "    for i, label in enumerate(db.labels_):\n",
    "        if label != -1: #ignore noise points\n",
    "            clusters_to_ret[label].append(urls[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # only do this if you need to print out the result (messy for large number of docs)\n",
    "    if verbose:\n",
    "        print(\"##Clusters##\")\n",
    "        clusters = {label: [] for label in db.labels_ if label!=-1}\n",
    "        noise = []\n",
    "        for i, label in enumerate(db.labels_):\n",
    "            if label != -1: \n",
    "                clusters[label].append(titles[i])\n",
    "            else: # save noise points\n",
    "                noise.append(titles[i])\n",
    "                \n",
    "        for label, list_ in clusters.items():\n",
    "            print(\"Cluster: {}\".format(list_))\n",
    "        if print_noise:\n",
    "            print(\"Noise: \", noise)\n",
    "\n",
    "        print(\"DBSCAN finished.\\n\")\n",
    "    return db, clusters_to_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer Vectors from docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_vectors(vectors):\n",
    "    \"\"\"given a list of (entities) vectors, return the simplest mean of vectors.\"\"\"\n",
    "    \n",
    "    if len(vectors)==0:\n",
    "        print(\"This document doesn't contain any known entity\")\n",
    "        return np.array([])\n",
    "    \n",
    "    # all vectors will have the same number of elements (features), \n",
    "    # which is equal to model.size\n",
    "    sum_vectors = np.zeros(np.shape(vectors[0]))\n",
    "    for vec in vectors:\n",
    "        sum_vectors = sum_vectors + vec\n",
    "    return sum_vectors/len(vectors)\n",
    "\n",
    "def infer_vector(entities, model):\n",
    "    \"\"\"Given a list of entities, returns the vector representing the documents from which the entities \n",
    "    were extracted from, wrt a given W2V model.\n",
    "    \n",
    "    entities: list of entities, our way of representing a document.\n",
    "    model: w2v model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get word vector of each entity; ignores word if the model does not know it\n",
    "    entities_vecs = []\n",
    "    unknown_words = 0\n",
    "    for e in entities:\n",
    "        try:\n",
    "            entities_vecs.append(model[e])\n",
    "        except:\n",
    "            unknown_words += 1 # ignore unknown word\n",
    "    if unknown_words > 0:\n",
    "        print(\"Number of unknown words for this doc: %s; known words %s\"%(unknown_words, len(entities)-unknown_words))\n",
    "    return mean_of_vectors(entities_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics.pairwise as sk # for cosine_distance\n",
    "# TODO: add possibility of passing metric to use as parameters\n",
    "\n",
    "def get_pairwise_distances_matrix(docs, model, verbose = False):\n",
    "    \"\"\"\"\n",
    "        docs: list of documents, each represented as a list of entities.\n",
    "        model: w2v model used to fetch the representation of entities as word vectors.\n",
    "        verbose: print out operations.\n",
    "        \n",
    "        Returns the pairwise distances matrix between documents. \n",
    "        Distance between 2 docs will be computed by averaging the distances between all words\n",
    "        composing the 2 documents.\n",
    "        Metric used is the one used in group_averaging_distance.\n",
    "    \"\"\"\n",
    "    # initialize distance matrix\n",
    "    n = len(docs)\n",
    "    distances_m = np.zeros((n, n))\n",
    "    \n",
    "    # un-wrap each set of entities (doc) and compute the distance betweem them all\n",
    "    # this is all but efficient at the moment, okay for a debug version.\n",
    "    for i, doc1 in enumerate(docs):\n",
    "        if verbose: print(\"##Calculating distances from \", doc1)\n",
    "        for j, doc2 in enumerate(docs):\n",
    "            distances_m[i, j] = group_averaging_distance(entities_vector(doc1, model), entities_vector(doc2, model))\n",
    "            if verbose: print(\"Distance between %s and %s: %s\"%(doc1, doc2, distances_m[i, j]))\n",
    "    return distances_m\n",
    "    \n",
    "def group_averaging_distance(doc1, doc2):\n",
    "    \"\"\"\n",
    "        Computes and returns the distance between 2 'sets'/lists of vectors, \n",
    "        by computing the distance between a vector in doc1 and all the other in doc2,\n",
    "        and averaging all these distances.\n",
    "        Metric used to compute distance is the cosine_distance -by default-.\n",
    "    \"\"\"\n",
    "    sum_of_distances = 0\n",
    "    for vec1 in doc1:\n",
    "        for vec2 in doc2:\n",
    "            sum_of_distances += sk.cosine_distances([vec1], [vec2])\n",
    "    return sum_of_distances/(len(doc1) * len(doc2))\n",
    "\n",
    "def entities_vector(doc, model):\n",
    "    \"\"\"\"\n",
    "    Doc: document, represented as a list of entities.\n",
    "    model: w2v model used to fetch representation of each vector.\n",
    "    \n",
    "    Given these two arguments, returns a list of vectors, each vector representing \n",
    "    an entity word.\n",
    "    In case the model does NOT know the word in the list, it will be ignored.\n",
    "    Might return an empty list.\n",
    "    \"\"\"\n",
    "    unknown_words = 0\n",
    "    list_ = []\n",
    "    for word in doc:\n",
    "        try:\n",
    "            v = model[word]\n",
    "            list_.append(v)\n",
    "        except:\n",
    "            unknown_words += 1\n",
    "    print(\"Unknown words: %s; Known words: %s\" %(unknown_words, len(doc)-unknown_words))\n",
    "    return list_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown words for this doc: 18; known words 17\n",
      "Number of unknown words for this doc: 38; known words 27\n",
      "Number of unknown words for this doc: 24; known words 19\n",
      "Number of unknown words for this doc: 21; known words 20\n",
      "Number of unknown words for this doc: 5; known words 8\n",
      "Number of unknown words for this doc: 28; known words 15\n",
      "Number of unknown words for this doc: 25; known words 21\n",
      "Number of unknown words for this doc: 38; known words 32\n",
      "Number of unknown words for this doc: 7; known words 9\n",
      "Number of unknown words for this doc: 1; known words 2\n",
      "##Clusters##\n",
      "Cluster: ['Stampa 3D in metallo, HP si lancia nella produzione di massa', 'Moreschini (Microsoft): Blockchain e Cloud accoppiata vincente per la PA - Blockchain 4innovation', \"Nokia volta pagina e punta (anche) sull'Iot: acquisita SpaceTime Insight - CorCom\", 'White Paper selection: Siemens spiega lâuso di MindSphere per lâIoT in ottica Industry 4.0', \"Pontremoli, Dallara: la vera innovazione nell'IoT e nell'Industria 4.0? Impossibile se non si coltiva l'eccellenza del territorio\", 'Cybersecurity, raddoppiano gli attacchi a reti e dispositivi IoT - CorCom', 'Industry 4.0, ecco che cosa chiedono le aziende (dopo gli incentivi)', 'Blockchain per rendere la PA piÃ¹ trasparente. Ecco come - Blockchain 4innovation']\n",
      "Noise:  ['Automazione: Fujitsu inaugura il software robot âas a serviceâ - Industry4Business', 'Smart Contract e blockchain - Pagina 4 di 5 - Blockchain 4innovation']\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "def lower_case_list(list_):\n",
    "    for i, word in enumerate(list_):\n",
    "        list_[i] = word.lower()\n",
    "    return list_\n",
    "# shuffle docs to get a random sub-sample\n",
    "random.shuffle(docs)\n",
    "\n",
    "subsample_length = 10\n",
    "subsample = docs[:subsample_length]\n",
    "subsample_titles = [doc['title'] for doc in subsample]\n",
    "sub_urls = [doc['url'] for doc in subsample]\n",
    "\n",
    "\n",
    "# get flattened_entities for each document, AS LIST of words (not a single string)\n",
    "#doc_entities = [doc['flattened_entities'].split() for doc in subsample]\n",
    "doc_entities = [lower_case_list(doc['result_entities']) for doc in subsample]\n",
    "#print(doc_entities[:1])\n",
    "\n",
    "# now we have to 'convert' every doc to vector form\n",
    "docs_vecs = [infer_vector(list_ent, model) for list_ent in doc_entities]\n",
    "\n",
    "# eps-visually chosen\n",
    "eps = 0.16\n",
    "\n",
    "db, clusters = perform_dbscan(eps = eps, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                data = docs_vecs, verbose = True, titles = subsample_titles, urls = sub_urls, print_noise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#print(docs[1])\n",
    "a = np.array([1,2])\n",
    "print(np.zeros(a.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN with matrix of distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:55: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 18; Known words: 17\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 38; Known words: 27\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 24; Known words: 19\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 21; Known words: 20\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 5; Known words: 8\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 28; Known words: 15\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 25; Known words: 21\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 38; Known words: 32\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 7; Known words: 9\n",
      "Unknown words: 1; Known words: 2\n",
      "Unknown words: 1; Known words: 2\n",
      "##Clusters##\n",
      "Cluster: ['Stampa 3D in metallo, HP si lancia nella produzione di massa', 'Moreschini (Microsoft): Blockchain e Cloud accoppiata vincente per la PA - Blockchain 4innovation', \"Nokia volta pagina e punta (anche) sull'Iot: acquisita SpaceTime Insight - CorCom\", 'White Paper selection: Siemens spiega lâuso di MindSphere per lâIoT in ottica Industry 4.0', 'Automazione: Fujitsu inaugura il software robot âas a serviceâ - Industry4Business', \"Pontremoli, Dallara: la vera innovazione nell'IoT e nell'Industria 4.0? Impossibile se non si coltiva l'eccellenza del territorio\", 'Cybersecurity, raddoppiano gli attacchi a reti e dispositivi IoT - CorCom', 'Industry 4.0, ecco che cosa chiedono le aziende (dopo gli incentivi)', 'Blockchain per rendere la PA piÃ¹ trasparente. Ecco come - Blockchain 4innovation', 'Smart Contract e blockchain - Pagina 4 di 5 - Blockchain 4innovation']\n",
      "Noise:  []\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = get_pairwise_distances_matrix(doc_entities, model, False)\n",
    "\n",
    "db, clusters = perform_dbscan(eps = 0.3, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                data = matrix, verbose = True, titles = subsample_titles, urls = sub_urls, print_noise = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

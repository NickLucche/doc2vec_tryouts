{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how testing is going to work\n",
    "Take 3 documents: 2 similar, and a 1 quite different; check if model recognizes this difference,\n",
    "which results, in the live version, to not group the three articles in the same region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 sample documents (articles) \n",
    "data = [\"Un incendio è scoppiato, nel tardo pomeriggio di ieri, nella zona delle cave a Bozzano, nel padule di Massarosa. Sul posto sono intervenuti i vigili del fuoco per domare l’incendio. Un odore di bruciato si è levato nella serata dalla zona delle fiamme fino ad invadere Viareggio, tra le proteste dei cittadini.\",\n",
    "       \"Spento l'incendio nel Compitese, ora la bonifica Lucca: sotto controllo gli ultimi focolai nella zona di San Leonardo in Treponzio. L'ipotesi più accreditata sull'origine rimane quella del fulmine.  La situazione, nella mattinata di martedì 2 ottobre, ha visto l'incendio praticamente domato, a parte alcuni focolai che comunque non destano preoccupazione. E' così potuta partire l'operazione di bonifica, grazie a due squadre dell'antincendio boschivo. Per quanto riguarda le cause del rogo, partito dalla zona di Pieve di Compito e poi arrivato fino a San Leonardo in treponzio, al momento una delle più accreditate resta quella del fulmine caduto durante il temporale di lunedì notte. Le forze dell'ordine, comunque, non escludono alcuna possibilità e per questo stanno cercando la presenza di eventuali inneschi.\",\n",
    "        \"Borse deboli, continua effetto Powell su titoli di Stato. Spread stabile a 280. Le Borse europee aprono la seduta tutte in flessione mentre proseguono le vendite sui titoli di Stato europei in scia a quanto avvenuto ieri dopo le parole del presidente della Fed Powell sulla possibile accelerazione nella stretta monetaria Usa. Piazza Affari perde mezzo punto percentuale nel FTSE MIB mentre gli altri indici continentali mostrano cali lievemente più contenuti (seguine qui l'andamento). In fondo al listino milanese StMicroelectronics, Saipem e Leonardo tra i titoli industriali ma anche il comparto bancario (visto il rendimento del decennale sempre in area 3,35%) con Banco Bpm. Intesa Sanpaolo e Ubi giù di un punto percentuale. Brillano Moncler (+2,2%) e Eni (+0,9%). Ieri intanto il Governo Conte ha rilasciato il Documento di Economia e di Finanza prevedendo una crescita dell'economia italiana all'1,5% nel 2019 e all'1,6% nell'anno successivo. \"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['un', 'incendio', 'scoppiato', 'nel', 'tardo', 'pomeriggio', 'di', 'ieri', 'nella', 'zona', 'delle', 'cave', 'bozzano', 'nel', 'padule', 'di', 'massarosa', 'sul', 'posto', 'sono', 'intervenuti', 'vigili', 'del', 'fuoco', 'per', 'domare', 'incendio', 'un', 'odore', 'di', 'bruciato', 'si', 'levato', 'nella', 'serata', 'dalla', 'zona', 'delle', 'fiamme', 'fino', 'ad', 'invadere', 'viareggio', 'tra', 'le', 'proteste', 'dei', 'cittadini'], ['spento', 'incendio', 'nel', 'compitese', 'ora', 'la', 'bonifica', 'lucca', 'sotto', 'controllo', 'gli', 'ultimi', 'focolai', 'nella', 'zona', 'di', 'san', 'leonardo', 'in', 'treponzio', 'ipotesi', 'più', 'accreditata', 'sull', 'origine', 'rimane', 'quella', 'del', 'fulmine', 'la', 'situazione', 'nella', 'mattinata', 'di', 'martedì', 'ottobre', 'ha', 'visto', 'incendio', 'praticamente', 'domato', 'parte', 'alcuni', 'focolai', 'che', 'comunque', 'non', 'destano', 'preoccupazione', 'così', 'potuta', 'partire', 'operazione', 'di', 'bonifica', 'grazie', 'due', 'squadre', 'dell', 'antincendio', 'boschivo', 'per', 'quanto', 'riguarda', 'le', 'cause', 'del', 'rogo', 'partito', 'dalla', 'zona', 'di', 'pieve', 'di', 'compito', 'poi', 'arrivato', 'fino', 'san', 'leonardo', 'in', 'treponzio', 'al', 'momento', 'una', 'delle', 'più', 'accreditate', 'resta', 'quella', 'del', 'fulmine', 'caduto', 'durante', 'il', 'temporale', 'di', 'lunedì', 'notte', 'le', 'forze', 'dell', 'ordine', 'comunque', 'non', 'escludono', 'alcuna', 'possibilità', 'per', 'questo', 'stanno', 'cercando', 'la', 'presenza', 'di', 'eventuali', 'inneschi'], ['borse', 'deboli', 'continua', 'effetto', 'powell', 'su', 'titoli', 'di', 'stato', 'spread', 'stabile', 'le', 'borse', 'europee', 'aprono', 'la', 'seduta', 'tutte', 'in', 'flessione', 'mentre', 'proseguono', 'le', 'vendite', 'sui', 'titoli', 'di', 'stato', 'europei', 'in', 'scia', 'quanto', 'avvenuto', 'ieri', 'dopo', 'le', 'parole', 'del', 'presidente', 'della', 'fed', 'powell', 'sulla', 'possibile', 'accelerazione', 'nella', 'stretta', 'monetaria', 'usa', 'piazza', 'affari', 'perde', 'mezzo', 'punto', 'percentuale', 'nel', 'ftse', 'mib', 'mentre', 'gli', 'altri', 'indici', 'continentali', 'mostrano', 'cali', 'lievemente', 'più', 'contenuti', 'seguine', 'qui', 'andamento', 'in', 'fondo', 'al', 'listino', 'milanese', 'saipem', 'leonardo', 'tra', 'titoli', 'industriali', 'ma', 'anche', 'il', 'comparto', 'bancario', 'visto', 'il', 'rendimento', 'del', 'decennale', 'sempre', 'in', 'area', 'con', 'banco', 'bpm', 'intesa', 'sanpaolo', 'ubi', 'giù', 'di', 'un', 'punto', 'percentuale', 'brillano', 'moncler', 'eni', 'ieri', 'intanto', 'il', 'governo', 'conte', 'ha', 'rilasciato', 'il', 'documento', 'di', 'economia', 'di', 'finanza', 'prevedendo', 'una', 'crescita', 'dell', 'economia', 'italiana', 'all', 'nel', 'all', 'nell', 'anno', 'successivo']]\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec imports\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim\n",
    "\n",
    "# sanitize data\n",
    "data = [gensim.utils.simple_preprocess(doc) for doc in data]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and infer vectors from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import  gensim\n",
    "\n",
    "MODEL_NAME = 'TestModels/d2v_TA_abstract&title0.model'\n",
    "MODEL_TWO = 'Models/d2v_TA_abstract&title0.model'\n",
    "model = Doc2Vec.load(MODEL_NAME)\n",
    "#model = Doc2Vec.load(MODEL_TWO)\n",
    "inferred_vectors = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in data:\n",
    "    # takes a list of strings\n",
    "    #inferred_vectors.append(np.array(model.infer_vector(doc)).reshape(1, -1))\n",
    "    inferred_vectors.append(model.infer_vector(doc))\n",
    "\n",
    "# cosine similarity\n",
    "print(cosine_similarity([inferred_vectors[0]], [inferred_vectors[1]])) # the similar documents\n",
    "print(cosine_similarity([inferred_vectors[0]], [inferred_vectors[2]]))\n",
    "print(cosine_similarity([inferred_vectors[1]], [inferred_vectors[2]]))\n",
    "print(gensim.models.cosine_similarity([inferred_vectors[0], inferred_vectors[1]]))\n",
    "# euclidean distance\n",
    "print(np.linalg.norm(inferred_vectors[0]-inferred_vectors[1])) # the similar documents\n",
    "print(np.linalg.norm(inferred_vectors[0]-inferred_vectors[2])) \n",
    "print(np.linalg.norm(inferred_vectors[1]-inferred_vectors[2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wikipedia articles test-set\n",
    "other approach: DBSCAN the vectors inferred from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 27 articles\n",
      "Lampone is similar to Ciliegia with a score of: [[0.531212]]\n",
      "\n",
      "Italia is similar to Berlino with a score of: [[0.57929134]]\n",
      "\n",
      "Italia is similar to Colosseo with a score of: [[0.538211]]\n",
      "\n",
      "Italia is similar to Parigi with a score of: [[0.57991326]]\n",
      "\n",
      "Italia is similar to Bologna with a score of: [[0.5998037]]\n",
      "\n",
      "Italia is similar to Roma with a score of: [[0.6075661]]\n",
      "\n",
      "Italia is similar to Milano with a score of: [[0.57625943]]\n",
      "\n",
      "Berlino is similar to Italia with a score of: [[0.57929134]]\n",
      "\n",
      "Berlino is similar to Parigi with a score of: [[0.6772896]]\n",
      "\n",
      "Berlino is similar to Londra with a score of: [[0.58199894]]\n",
      "\n",
      "Berlino is similar to Bologna with a score of: [[0.5809386]]\n",
      "\n",
      "Berlino is similar to Roma with a score of: [[0.6819624]]\n",
      "\n",
      "Berlino is similar to Milano with a score of: [[0.5700284]]\n",
      "\n",
      "Colosseo is similar to Italia with a score of: [[0.538211]]\n",
      "\n",
      "Colosseo is similar to New York with a score of: [[0.52936727]]\n",
      "\n",
      "Colosseo is similar to Parigi with a score of: [[0.5569618]]\n",
      "\n",
      "Colosseo is similar to Londra with a score of: [[0.504785]]\n",
      "\n",
      "Colosseo is similar to Bologna with a score of: [[0.5256399]]\n",
      "\n",
      "Colosseo is similar to Roma with a score of: [[0.5459777]]\n",
      "\n",
      "Colosseo is similar to Pizza with a score of: [[0.5452397]]\n",
      "\n",
      "Colosseo is similar to Quirinale with a score of: [[0.5141779]]\n",
      "\n",
      "New York is similar to Colosseo with a score of: [[0.52936727]]\n",
      "\n",
      "New York is similar to Parigi with a score of: [[0.6068636]]\n",
      "\n",
      "New York is similar to Bologna with a score of: [[0.50609374]]\n",
      "\n",
      "Ciliegia is similar to Lampone with a score of: [[0.531212]]\n",
      "\n",
      "Ciliegia is similar to Melone with a score of: [[0.5167227]]\n",
      "\n",
      "Mela is similar to Melone with a score of: [[0.50334686]]\n",
      "\n",
      "Parigi is similar to Italia with a score of: [[0.57991326]]\n",
      "\n",
      "Parigi is similar to Berlino with a score of: [[0.6772896]]\n",
      "\n",
      "Parigi is similar to Colosseo with a score of: [[0.5569618]]\n",
      "\n",
      "Parigi is similar to New York with a score of: [[0.6068636]]\n",
      "\n",
      "Parigi is similar to Londra with a score of: [[0.5020352]]\n",
      "\n",
      "Parigi is similar to Bologna with a score of: [[0.64245003]]\n",
      "\n",
      "Parigi is similar to Roma with a score of: [[0.68565685]]\n",
      "\n",
      "Parigi is similar to Milano with a score of: [[0.56359047]]\n",
      "\n",
      "Parigi is similar to Quirinale with a score of: [[0.51029843]]\n",
      "\n",
      "Londra is similar to Berlino with a score of: [[0.58199894]]\n",
      "\n",
      "Londra is similar to Colosseo with a score of: [[0.504785]]\n",
      "\n",
      "Londra is similar to Parigi with a score of: [[0.5020352]]\n",
      "\n",
      "Londra is similar to Bologna with a score of: [[0.5169928]]\n",
      "\n",
      "Londra is similar to Roma with a score of: [[0.61605096]]\n",
      "\n",
      "Bologna is similar to Italia with a score of: [[0.5998037]]\n",
      "\n",
      "Bologna is similar to Berlino with a score of: [[0.5809386]]\n",
      "\n",
      "Bologna is similar to Colosseo with a score of: [[0.5256399]]\n",
      "\n",
      "Bologna is similar to New York with a score of: [[0.50609374]]\n",
      "\n",
      "Bologna is similar to Parigi with a score of: [[0.64245003]]\n",
      "\n",
      "Bologna is similar to Londra with a score of: [[0.5169928]]\n",
      "\n",
      "Bologna is similar to Roma with a score of: [[0.5947815]]\n",
      "\n",
      "Bologna is similar to Pizza with a score of: [[0.53606254]]\n",
      "\n",
      "Bologna is similar to Milano with a score of: [[0.59678006]]\n",
      "\n",
      "Bologna is similar to Quirinale with a score of: [[0.5079976]]\n",
      "\n",
      "Roma is similar to Italia with a score of: [[0.6075661]]\n",
      "\n",
      "Roma is similar to Berlino with a score of: [[0.6819624]]\n",
      "\n",
      "Roma is similar to Colosseo with a score of: [[0.5459777]]\n",
      "\n",
      "Roma is similar to Parigi with a score of: [[0.68565685]]\n",
      "\n",
      "Roma is similar to Londra with a score of: [[0.61605096]]\n",
      "\n",
      "Roma is similar to Bologna with a score of: [[0.5947815]]\n",
      "\n",
      "Roma is similar to Pizza with a score of: [[0.50858974]]\n",
      "\n",
      "Roma is similar to Milano with a score of: [[0.6229526]]\n",
      "\n",
      "Roma is similar to Quirinale with a score of: [[0.51453173]]\n",
      "\n",
      "Melone is similar to Ciliegia with a score of: [[0.5167227]]\n",
      "\n",
      "Melone is similar to Mela with a score of: [[0.50334686]]\n",
      "\n",
      "Melone is similar to Banana with a score of: [[0.5124017]]\n",
      "\n",
      "Banana is similar to Melone with a score of: [[0.5124017]]\n",
      "\n",
      "Pizza is similar to Colosseo with a score of: [[0.5452397]]\n",
      "\n",
      "Pizza is similar to Bologna with a score of: [[0.53606254]]\n",
      "\n",
      "Pizza is similar to Roma with a score of: [[0.50858974]]\n",
      "\n",
      "Pizza is similar to Milano with a score of: [[0.5207414]]\n",
      "\n",
      "Milano is similar to Italia with a score of: [[0.57625943]]\n",
      "\n",
      "Milano is similar to Berlino with a score of: [[0.5700284]]\n",
      "\n",
      "Milano is similar to Parigi with a score of: [[0.56359047]]\n",
      "\n",
      "Milano is similar to Bologna with a score of: [[0.59678006]]\n",
      "\n",
      "Milano is similar to Roma with a score of: [[0.6229526]]\n",
      "\n",
      "Milano is similar to Pizza with a score of: [[0.5207414]]\n",
      "\n",
      "Quirinale is similar to Colosseo with a score of: [[0.5141779]]\n",
      "\n",
      "Quirinale is similar to Parigi with a score of: [[0.51029843]]\n",
      "\n",
      "Quirinale is similar to Bologna with a score of: [[0.5079976]]\n",
      "\n",
      "Quirinale is similar to Roma with a score of: [[0.51453173]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('wikipedia_dump.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "print(\"We have {} articles\".format(len(json_data)))\n",
    "titles = []\n",
    "inferred_vectors = []\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "for dictionary in json_data:\n",
    "    inferred_vectors.append(model.infer_vector(gensim.utils.simple_preprocess(dictionary['abstract'])))\n",
    "    titles.append(dictionary['title'])\n",
    "assert len(titles)==len(inferred_vectors)\n",
    "\n",
    "# for now, let's just print out documents similiraties among them\n",
    "for i, docvec in enumerate(inferred_vectors):\n",
    "    for j, docv in enumerate(inferred_vectors):\n",
    "        # let's just write out the most similar vectors\n",
    "        sim = cosine_similarity([docvec], [docv])\n",
    "        if sim>=similarity_threshold and i != j:\n",
    "            print(\"{0} is similar to {1} with a score of: {2}\\n\".format(titles[i], titles[j], sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def perform_dbscan(eps = 0.4, min_samples = 4, metric = 'euclidean', algorithm = 'auto', data = None, verbose = True):\n",
    "    \"\"\"perform DBSCAN over given data, using given parametrs. Returns dbscan object.\"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm).fit(data)\n",
    "\n",
    "    #print(\"Core samples: \")\n",
    "    #for i in db.core_sample_indices_ :\n",
    "    #    print(titles[i]+\"\\n\")\n",
    "\n",
    "    # labels will print out the number of the cluster each example belongs to;\n",
    "    # -1 if the vector is considered noise (not belonging to any cluster)\n",
    "    #print(\"Labels: \", db.labels_)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"##Clusters##\")\n",
    "        cluster = [[]]\n",
    "        noise = []\n",
    "        noise_r = []\n",
    "        for i, label in enumerate(db.labels_):\n",
    "            if label != -1:\n",
    "                try:\n",
    "                    cluster[label].append(titles[i])\n",
    "                except Exception as e:\n",
    "                    cluster.append([titles[i]])\n",
    "            else:\n",
    "                noise.append(titles[i])\n",
    "                noise_r.append(i)\n",
    "        for list_ in cluster:\n",
    "            print(\"Cluster:\", list_)\n",
    "        print(\"Noise: \", noise)\n",
    "\n",
    "        print(\"DBSCAN finished.\\n\")\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Clusters##\n",
      "Cluster: ['Lampone', 'Ciliegia', 'Mela', 'Melone', 'Banana']\n",
      "Cluster: ['Italia', 'Berlino', 'Colosseo', 'New York', 'Parigi', 'Londra', 'Bologna', 'Roma', 'Pizza', 'Milano', 'Quirinale']\n",
      "Noise:  ['Microsoft', 'Casa Bianca', 'Amazon', 'Instagram', 'Pasta', 'Facebook', 'USA', 'Pera', 'Google', 'Apple', 'Hot dog']\n",
      "DBSCAN finished.\n",
      "\n",
      "##Clusters##\n",
      "Cluster: ['Italia', 'Berlino', 'Colosseo', 'New York', 'Parigi', 'Londra', 'Bologna', 'Roma', 'Milano']\n",
      "Noise:  ['Microsoft', 'Lampone', 'Casa Bianca', 'Amazon', 'Instagram', 'Ciliegia', 'Mela', 'Pasta', 'Melone', 'Banana', 'Facebook', 'USA', 'Pizza', 'Quirinale', 'Pera', 'Google', 'Apple', 'Hot dog']\n",
      "DBSCAN finished.\n",
      "\n",
      "##Clusters##\n",
      "Cluster: ['Microsoft', 'Amazon', 'Apple']\n",
      "Cluster: ['Lampone', 'Casa Bianca', 'Italia', 'Berlino', 'Colosseo', 'New York', 'Ciliegia', 'Mela', 'Parigi', 'Londra', 'Bologna', 'Roma', 'Melone', 'Banana', 'USA', 'Pizza', 'Milano', 'Quirinale', 'Hot dog']\n",
      "Cluster: ['Instagram', 'Facebook']\n",
      "Noise:  ['Pasta', 'Pera', 'Google']\n",
      "DBSCAN finished.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12, 23, 24]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try out different options\n",
    "#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.3, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.5, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'euclidean', algorithm = 'auto', data = inferred_vectors)\n",
    "#perform_dbscan(eps = 0.2, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.45, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)\n",
    "perform_dbscan(eps = 0.55, min_samples = 2, metric = 'cosine', algorithm = 'auto', data = inferred_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia 3-documents-test\n",
    "Test our model with 2 similar documents, and one chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 18 docs tuples\n",
      "['Banana', 'Ciliegia', 'Riccardo Chiarini', 'Acqua', 'Ghiaccio', 'Let There Be Love', 'Fuoco', 'Fiamme', 'Gerónimo de Aguilar', 'Juventus', 'Real Madrid', 'Le tre scimmie', 'NASA', 'Marte', 'Sindaci di Brindisi', 'Vento', 'Uragano', 'Au4', 'Roma', 'Berlino', 'Jean de Locquenghien', 'iPad', 'iPhone', 'Chibly Langlois', 'Apple', 'Microsoft', 'Chiesa di Santo Stefano (Miglieglia)', 'Google', 'Amazon', 'Hauntology', 'Mela', 'Pera', 'Sin gisaeng dyeon', 'Lampone', 'Melone', 'Harrington (Washington)', 'Instagram', 'Facebook', 'Kevin Schmidt', 'Parigi', 'Londra', 'Schiava (vitigno)', 'Milano', 'Bologna', 'Decreto di attuazione degli statuti', 'Marte', 'Venere', 'Scotty 2 Hotty', 'Mark Zuckerberg', 'Facebook', 'Festival da Canção', 'Cometa', 'Stella', 'Miglioramento paretiano']\n"
     ]
    }
   ],
   "source": [
    "# 2 documents are similar if they get a score higher than this threshold\n",
    "# - based on cosine similarity -\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "# load file\n",
    "import json\n",
    "with open('wikipedia_3docs_dump.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "print(\"We have {} docs tuples\".format(len(json_data)))\n",
    "titles = []\n",
    "inferred_vectors = [] # list of lists\n",
    "\n",
    "# infer each document vector\n",
    "for dic_list in json_data:\n",
    "    vectors = []\n",
    "    for dictionary in dic_list:\n",
    "        vec = model.infer_vector(gensim.utils.simple_preprocess(dictionary['abstract']))\n",
    "        vectors.append(vec)\n",
    "        titles.append(dictionary['title'])\n",
    "    inferred_vectors.append(vectors)\n",
    "    \n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Banana, 'Ciliegia')---Riccardo Chiarini\n",
      "Similar 1-2 [[0.5008852]]\n",
      "('Acqua, 'Ghiaccio')---Let There Be Love\n",
      "Guessed right!\n",
      "('Fuoco, 'Fiamme')---Gerónimo de Aguilar\n",
      "Similar 0-2 [[0.5075566]]\n",
      "('Juventus, 'Real Madrid')---Le tre scimmie\n",
      "Guessed right!\n",
      "('NASA, 'Marte')---Sindaci di Brindisi\n",
      "Not similar  [[0.44681236]]\n",
      "('Vento, 'Uragano')---Au4\n",
      "Not similar  [[0.4374466]]\n",
      "('Roma, 'Berlino')---Jean de Locquenghien\n",
      "Guessed right!\n",
      "('iPad, 'iPhone')---Chibly Langlois\n",
      "Guessed right!\n",
      "('Apple, 'Microsoft')---Chiesa di Santo Stefano (Miglieglia)\n",
      "Guessed right!\n",
      "('Google, 'Amazon')---Hauntology\n",
      "Not similar  [[0.3489512]]\n",
      "('Mela, 'Pera')---Sin gisaeng dyeon\n",
      "Guessed right!\n",
      "('Lampone, 'Melone')---Harrington (Washington)\n",
      "Not similar  [[0.42072335]]\n",
      "('Instagram, 'Facebook')---Kevin Schmidt\n",
      "Not similar  [[0.42628554]]\n",
      "('Parigi, 'Londra')---Schiava (vitigno)\n",
      "Guessed right!\n",
      "('Milano, 'Bologna')---Decreto di attuazione degli statuti\n",
      "Guessed right!\n",
      "('Marte, 'Venere')---Scotty 2 Hotty\n",
      "Guessed right!\n",
      "('Mark Zuckerberg, 'Facebook')---Festival da Canção\n",
      "Guessed right!\n",
      "('Cometa, 'Stella')---Miglioramento paretiano\n",
      "Guessed right!\n",
      "Correct guesses: 11 over 18 examples\n"
     ]
    }
   ],
   "source": [
    "# a model gives a correct answer if it correctly classifies the 2 'linked-document' \n",
    "# as similar, and the third one as dissimilar to both\n",
    "correct = 0\n",
    "j = 0\n",
    "for i, linked_docs in enumerate(inferred_vectors):\n",
    "    print(\"('{0}, '{1}')---{2}\".format(titles[j], titles[j+1], titles[j+2]))\n",
    "    j = j+3\n",
    "    cosine_s = cosine_similarity([linked_docs[0]], [linked_docs[1]])\n",
    "    if cosine_s<similarity_threshold:\n",
    "        print(\"Not similar \", cosine_s)\n",
    "        continue\n",
    "    cosine_s = cosine_similarity([linked_docs[0]], [linked_docs[2]])\n",
    "    if cosine_s > similarity_threshold:\n",
    "        print(\"Similar 0-2\", cosine_s)\n",
    "        continue\n",
    "    cosine_s = cosine_similarity([linked_docs[1]], [linked_docs[2]])\n",
    "    if cosine_s > similarity_threshold:\n",
    "        print(\"Similar 1-2\", cosine_s)\n",
    "        continue\n",
    "    correct = correct + 1\n",
    "    print(\"Guessed right!\")\n",
    "    \n",
    "print(\"Correct guesses: {0} over {1} examples\".format(correct, len(inferred_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out test corpus Clustering and Visualization\n",
    "kind of a live-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  200\n"
     ]
    }
   ],
   "source": [
    "## load test-corpus\n",
    "import json\n",
    "import gensim\n",
    "\n",
    "with open('TOWL_test_corpus.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "# we're expecting a list\n",
    "assert isinstance(json_data, list)\n",
    "titles = [dictionary['title'] for dictionary in json_data]\n",
    "test_corpus = [gensim.utils.simple_preprocess(d['title']+d['abstract']) for d in json_data]\n",
    "print(\"Number of documents: \", len(test_corpus))\n",
    "#print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for each document in the test corpus, infer a vector\n",
    "inferred_vectors = [model.infer_vector(test_doc) for test_doc in test_corpus]\n",
    "# and perform db scan\n",
    "db = perform_dbscan(eps = 0.25, min_samples = 2, metric = 'cosine', algorithm = 'auto',\n",
    "                    data = inferred_vectors, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualizing using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# loading dataset into Pandas DataFrame\n",
    "df = pd.DataFrame.from_records(inferred_vectors)\n",
    "# PCA is effected by scale so you need to scale the features in your data before applying PCA. \n",
    "vec_size = 100\n",
    "features = [i for i in range(vec_size)]\n",
    "\n",
    "x = df.loc[:, features].values # get features values\n",
    "# standardize data\n",
    "x = StandardScaler().fit_transform(x) # scale data (especially in case different measures are used)\n",
    "# build PCA model in 2D\n",
    "pca = PCA(n_components=2) # The new components are just the two main dimensions of variation.\n",
    "\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf.head()\n",
    "# these components drawn don't hold a lot of information 'per-se', they're just the result \n",
    "# of dimension-reduction\n",
    "\n",
    "finalDf = principalDf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~D4nt3/42.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "from scipy.spatial import distance\n",
    "\n",
    "tls.set_credentials_file(username='D4nt3', api_key='FdMB4O6qCfciGDOnLvdQ')\n",
    "\n",
    "COMPONENT_ONE = \"principal component 1\"\n",
    "COMPONENT_TWO = \"principal component 2\"\n",
    "\n",
    "titles = [dictionary['title'] for dictionary in json_data]\n",
    "traces = []\n",
    "clusters_indices = db.labels_\n",
    "\n",
    "assert len(finalDf)==len(clusters_indices)\n",
    "# each trace will represent a point (squeezed vector from higher dimensions),\n",
    "# and each point will have the title of the news assigned\n",
    "for i in range(len(finalDf)):\n",
    "    x , y = finalDf.iat[i, 0], finalDf.iat[i, 1]\n",
    "    color = 'rgba(0, 0, 180, 0.8)'\n",
    "    \n",
    "    # print colors according to cluster\n",
    "    if clusters_indices[i]==0:\n",
    "        color = 'red'\n",
    "    elif clusters_indices[i]==1:\n",
    "        color = 'pink'\n",
    "    elif clusters_indices[i]==2:\n",
    "        color = 'yellow'\n",
    "    elif clusters_indices[i]==3:\n",
    "        color = 'blue'\n",
    "    elif clusters_indices[i]==4:\n",
    "        color = 'violet'\n",
    "    elif clusters_indices[i]==-1:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    \n",
    "    trace0 = go.Scatter(\n",
    "        x = [x], \n",
    "        y = [y],\n",
    "        mode = 'markers',\n",
    "            #name = 'blue markers',\n",
    "        marker = dict(\n",
    "            size = 7,\n",
    "            color = color,\n",
    "        ),\n",
    "        text = str(titles[i])\n",
    "    )\n",
    "    traces.append(trace0)\n",
    "\n",
    "data = traces \n",
    "layout = dict(title = 'PCA Representantion of Test Data with DBSCAN',\n",
    "            hovermode= 'closest',\n",
    "            xaxis= dict(\n",
    "                title= 'first component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title= 'second component',\n",
    "                ticklen= 5,\n",
    "                gridwidth= 2,\n",
    "            ),\n",
    "            showlegend = False\n",
    "        )\n",
    "# Plot and embed in ipython notebook!\n",
    "    \n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename='TOWL_model_testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
